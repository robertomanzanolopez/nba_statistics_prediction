{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7c6e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91c946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo primero, leemos el dataframe\n",
    "df = pd.read_csv('df_all_rs.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cc87b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df = df.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e6470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df.corr()\n",
    "plt.figure(figsize=(18,6))\n",
    "sns.heatmap(df_corr, annot=True, cmap='BrBG', center=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95f6800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6480c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['HOME_TEAM_WINS']\n",
    "data = df[['FG_PCT_home', 'FG_PCT_away', 'FG3_PCT_home', 'FG3_PCT_away']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579193c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc0d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(estimator, data, target):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data,target)\n",
    "\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_hat = estimator.predict(X_test)\n",
    "    probs = estimator.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # plotear curva roc\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "    f, ax = plt.subplots(1,1)\n",
    "    f.set_size_inches(8,7)\n",
    "    ax.plot(fpr,tpr)\n",
    "    ax.plot([0,1], [0,1], c='grey')\n",
    "\n",
    "    print(f'acc: {accuracy_score(y_test, y_hat):.3} \\\n",
    "    recall: {recall_score(y_test, y_hat):.3} \\\n",
    "    precision:{precision_score(y_test, y_hat):.3} \\\n",
    "    f1:{f1_score(y_test, y_hat):.3} \\\n",
    "    auc:{roc_auc_score(y_test, probs):.3}')\n",
    "\n",
    "logR = LogisticRegression()\n",
    "evaluate(logR, data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27daed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_results = pd.DataFrame(columns=['MSE','RMSE', \"MAE\"])\n",
    "\n",
    "def evaluar_metricas(estimator, data, target, name):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data,target)\n",
    "\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_hat = estimator.predict(X_test)\n",
    "\n",
    "    errors = y_test - y_hat\n",
    "    mae = np.mean(np.abs(errors))\n",
    "    mse = np.mean(errors ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    metrics_results.loc[name] = [mse,rmse,mae]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c54826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "kn = KNeighborsRegressor()\n",
    "dt = DecisionTreeRegressor()\n",
    "rf = RandomForestRegressor()\n",
    "mlpr = MLPRegressor()\n",
    "logR = LogisticRegression()\n",
    "\n",
    "evaluar_metricas(lr, data, target, 'lr')\n",
    "evaluar_metricas(kn, data, target, 'kn')\n",
    "evaluar_metricas(dt, data, target, 'dt')\n",
    "evaluar_metricas(rf, data, target, 'rf')\n",
    "evaluar_metricas(mlpr, data, target, 'mlpr')\n",
    "evaluar_metricas(logR, data, target, 'logR')\n",
    "\n",
    "metrics_results.style.highlight_min(color='lightgreen', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e92bbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A priori parace que los algoritmos que menos error dan son mlpr y logR\n",
    "# Esto es una primera prueba, no tenemos los datos normalizados si quiera\n",
    "# Asi que lo primero que vamos a hacer es normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = data.copy()\n",
    "normalized_data = (data_copy - data_copy.mean()) / data_copy.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36491d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a evaluar, pero ahora con los datos normalizados\n",
    "evaluar_metricas(lr, normalized_data, target, 'lr_normalized')\n",
    "evaluar_metricas(kn, normalized_data, target, 'kn_normalized')\n",
    "evaluar_metricas(dt, normalized_data, target, 'dt_normalized')\n",
    "evaluar_metricas(rf, normalized_data, target, 'rf_normalized')\n",
    "evaluar_metricas(mlpr, normalized_data, target, 'mlpr_normalized')\n",
    "evaluar_metricas(logR, normalized_data, target, 'logR_normalized')\n",
    "\n",
    "metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d27b562",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_results.style.highlight_min(color='lightgreen', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7114ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con los datos normalizados vemos que el algoritmo mlpr sigue siendo el que menos error tiene\n",
    "# Antes de decidirnos del todo por un algoritmo, vamos a a \"toquetear\" un poco cada uno,\n",
    "# jugar con sus parametros y demas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1793ee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a empezar con Kneighbors\n",
    "# Para ello modificamos un poco la funcion que teniamos antes para evaluar, para que nos guarde los resultados\n",
    "# en un dataframe distinto, uno solo para kn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd197f19",
   "metadata": {},
   "source": [
    "# kn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9e9b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_metrics = pd.DataFrame(columns=['MSE','RMSE', \"MAE\"])\n",
    "\n",
    "def evaluar_metricas_kn(estimator, data, target, name):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data,target)\n",
    "\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_hat = estimator.predict(X_test)\n",
    "\n",
    "    errors = y_test - y_hat\n",
    "    mae = np.mean(np.abs(errors))\n",
    "    mse = np.mean(errors ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    kn_metrics.loc[name] = [mse,rmse,mae]\n",
    "\n",
    "#for i in range(1, 50):\n",
    "    kn = KNeighborsRegressor(n_neighbors=i)\n",
    "    evaluar_metricas_kn(kn, normalized_data, target, 'kn_normalized_'+str(i))\n",
    "    \n",
    "#kn_metrics.style.highlight_min(color='lightgreen', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7943c7d",
   "metadata": {},
   "source": [
    "### Conclusión kn:\n",
    "#### n_neighbors es 29(MSE y RMSE)\n",
    "#### n_neighbors es 2(MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1fdd86",
   "metadata": {},
   "source": [
    "# dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a09b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_metrics = pd.DataFrame(columns=['MSE','RMSE', \"MAE\"])\n",
    "\n",
    "def evaluar_metricas_dt(estimator, data, target, name):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data,target)\n",
    "\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_hat = estimator.predict(X_test)\n",
    "\n",
    "    errors = y_test - y_hat\n",
    "    mae = np.mean(np.abs(errors))\n",
    "    mse = np.mean(errors ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    dt_metrics.loc[name] = [mse,rmse,mae]\n",
    "\n",
    "\n",
    "#for i in range(1, 50):\n",
    "    for j in range(1,10):\n",
    "        dt = DecisionTreeRegressor(max_depth=i, min_samples_leaf=j)\n",
    "        evaluar_metricas_dt(dt, normalized_data, target, 'dt_normalized_'+str(i)+str(j))\n",
    "        j += 1\n",
    "    i += 1\n",
    "    \n",
    "#dt_metrics.style.highlight_min(color='lightgreen', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9b0b24",
   "metadata": {},
   "source": [
    "### Conclusión dt:\n",
    "#### max_depth=6 y min_samples_leaf=2(MSE y RMSE)\n",
    "#### max_depth=25 y min_samples_leaf=3(MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87b5b54",
   "metadata": {},
   "source": [
    "# rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6286551",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_metrics = pd.DataFrame(columns=['MSE','RMSE', \"MAE\"])\n",
    "\n",
    "def evaluar_metricas_rf(estimator, data, target, name):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data,target)\n",
    "\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_hat = estimator.predict(X_test)\n",
    "\n",
    "    errors = y_test - y_hat\n",
    "    mae = np.mean(np.abs(errors))\n",
    "    mse = np.mean(errors ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    rf_metrics.loc[name] = [mse,rmse,mae]\n",
    "\n",
    "\n",
    "#for k in range(1,30):\n",
    "    for i in range(1, 50):\n",
    "        for j in range(1,10):\n",
    "            rf = RandomForestRegressor(n_estimators=k, max_depth=i, min_samples_leaf=j)\n",
    "            evaluar_metricas_rf(rf, normalized_data, target, 'rf_normalized_'+str(k)+str(i)+str(j))\n",
    "            j += 1\n",
    "        i += 1\n",
    "    k += 1\n",
    "\n",
    "#rf_metrics.style.highlight_min(color='lightgreen', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba276223",
   "metadata": {},
   "source": [
    "### Conclusión rf:\n",
    "#### minimo cuando: rf_normalized_16417 -> n_estimators=16, max_depth=41, min_samples_leaf=7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89add49",
   "metadata": {},
   "source": [
    "# logR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c4c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "logR_metrics = pd.DataFrame(columns=['MSE','RMSE', \"MAE\"])\n",
    "\n",
    "def evaluar_metricas_logR(estimator, data, target, name):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data,target)\n",
    "\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_hat = estimator.predict(X_test)\n",
    "\n",
    "    errors = y_test - y_hat\n",
    "    mae = np.mean(np.abs(errors))\n",
    "    mse = np.mean(errors ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    logR_metrics.loc[name] = [mse,rmse,mae]\n",
    "\n",
    "#for k in range(1,30):\n",
    "    for i in range(1, 50):\n",
    "        for j in range(1,10):\n",
    "            logR = logR = LogisticRegression()\n",
    "            evaluar_metricas_logR(logR, normalized_data, target, 'logR_normalized_'+str(k)+str(i)+str(j))\n",
    "            j += 1\n",
    "        i += 1\n",
    "    k += 1\n",
    "\n",
    "#logR_metrics.style.highlight_min(color='lightgreen', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee2d7ec",
   "metadata": {},
   "source": [
    "### Conclusión logR:\n",
    "#### minimo cuando:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1c59dc",
   "metadata": {},
   "source": [
    "# mlpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c8b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpr_metrics = pd.DataFrame(columns=['MSE','RMSE', \"MAE\"])\n",
    "\n",
    "def evaluar_metricas_mlpr(estimator, data, target, name):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data,target)\n",
    "\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_hat = estimator.predict(X_test)\n",
    "\n",
    "    errors = y_test - y_hat\n",
    "    mae = np.mean(np.abs(errors))\n",
    "    mse = np.mean(errors ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    mlpr_metrics.loc[name] = [mse,rmse,mae]\n",
    "\n",
    "#for k in range(1,30):\n",
    "    for i in range(1, 50):\n",
    "        for j in range(1,10):\n",
    "            mlpr = MLPRegressor()\n",
    "            evaluar_metricas_mlpr(mlpr, normalized_data, target, 'mlpr_normalized_'+str(k)+str(i)+str(j))\n",
    "            j += 1\n",
    "        i += 1\n",
    "    k += 1\n",
    "\n",
    "#mlpr_metrics.style.highlight_min(color='lightgreen', axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b08eca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Conclusión mlpr:\n",
    "#### minimo cuando:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
