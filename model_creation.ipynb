{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1e52c8d",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e3c30522",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12db858",
   "metadata": {},
   "source": [
    "### LOAD DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "628b3f32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>HOME_TEAM_ID</th>\n",
       "      <th>VISITOR_TEAM_ID</th>\n",
       "      <th>HOME_TEAM_ABBREVIATION</th>\n",
       "      <th>HOME_TEAM_NICKNAME</th>\n",
       "      <th>VISITOR_TEAM_ABBREVIATION</th>\n",
       "      <th>VISITOR_TEAM_NICKNAME</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>FG_PCT_home</th>\n",
       "      <th>FT_PCT_home</th>\n",
       "      <th>FG3_PCT_home</th>\n",
       "      <th>PERCENT_VIC_UNITL_THIS_GAME_HOME_TEAM</th>\n",
       "      <th>PERCENT_VIC_LAST5_GAMES_HOME_TEAM</th>\n",
       "      <th>PERCENT_VIC_LAST10_GAMES_HOME_TEAM</th>\n",
       "      <th>AVG_POINTS_UNTIL_THIS_GAME_HOME_TEAM</th>\n",
       "      <th>AVG_POINTS_LAST5_HOME_TEAM</th>\n",
       "      <th>AVG_POINTS_LAST10_HOME_TEAM</th>\n",
       "      <th>AVG_FGPERCENT_UNTIL_THIS_GAME_HOME_TEAM</th>\n",
       "      <th>AVG_FGPERCENT_LAST5_HOME_TEAM</th>\n",
       "      <th>AVG_FGPERCENT_LAST10_HOME_TEAM</th>\n",
       "      <th>AVG_FGPERCENT_LAST10_HOME_TEAM.1</th>\n",
       "      <th>AVG_FG3PCT_UNTIL_THIS_GAME_HOME_TEAM</th>\n",
       "      <th>AVG_FG3PCT_LAST5_HOME_TEAM</th>\n",
       "      <th>AVG_FG3PCT_LAST10_HOME_TEAM</th>\n",
       "      <th>AST_home</th>\n",
       "      <th>REB_home</th>\n",
       "      <th>FG_PCT_away</th>\n",
       "      <th>FT_PCT_away</th>\n",
       "      <th>FG3_PCT_away</th>\n",
       "      <th>PERCENT_VIC_UNITL_THIS_GAME_VISITOR_TEAM</th>\n",
       "      <th>PERCENT_VIC_LAST5_GAMES_VISITOR_TEAM</th>\n",
       "      <th>PERCENT_VIC_LAST10_GAMES_VISITOR_TEAM</th>\n",
       "      <th>AVG_POINTS_UNTIL_THIS_GAME_VISITOR_TEAM</th>\n",
       "      <th>AVG_POINTS_LAST5_VISITOR_TEAM</th>\n",
       "      <th>AVG_POINTS_LAST10_VISITOR_TEAM</th>\n",
       "      <th>AVG_FGPERCENT_UNTIL_THIS_GAME_VISITOR_TEAM</th>\n",
       "      <th>AVG_FGPERCENT_LAST5_VISITOR_TEAM</th>\n",
       "      <th>AVG_FGPERCENT_LAST10_VISITOR_TEAM</th>\n",
       "      <th>AVG_FGPERCENT_LAST10_VISITOR_TEAM.1</th>\n",
       "      <th>AVG_FG3PCT_UNTIL_THIS_GAME_VISITOR_TEAM</th>\n",
       "      <th>AVG_FG3PCT_LAST5_VISITOR_TEAM</th>\n",
       "      <th>AVG_FG3PCT_LAST10_VISITOR_TEAM</th>\n",
       "      <th>AST_away</th>\n",
       "      <th>REB_away</th>\n",
       "      <th>HOME_TEAM_WINS</th>\n",
       "      <th>VISITOR_TEAM_WINS</th>\n",
       "      <th>PTS_home</th>\n",
       "      <th>PTS_away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20300001</td>\n",
       "      <td>1610612755</td>\n",
       "      <td>1610612748</td>\n",
       "      <td>PHI</td>\n",
       "      <td>76ers</td>\n",
       "      <td>MIA</td>\n",
       "      <td>Heat</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003-10-28</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.350</td>\n",
       "      <td>40.243902</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>87.987805</td>\n",
       "      <td>88.0</td>\n",
       "      <td>84.3</td>\n",
       "      <td>0.429683</td>\n",
       "      <td>0.4656</td>\n",
       "      <td>0.4251</td>\n",
       "      <td>0.4251</td>\n",
       "      <td>0.335171</td>\n",
       "      <td>0.2914</td>\n",
       "      <td>0.3069</td>\n",
       "      <td>25.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.250</td>\n",
       "      <td>51.219512</td>\n",
       "      <td>80.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>90.268293</td>\n",
       "      <td>94.0</td>\n",
       "      <td>93.6</td>\n",
       "      <td>0.426366</td>\n",
       "      <td>0.4210</td>\n",
       "      <td>0.4185</td>\n",
       "      <td>0.4185</td>\n",
       "      <td>0.358317</td>\n",
       "      <td>0.3632</td>\n",
       "      <td>0.3776</td>\n",
       "      <td>16.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20300002</td>\n",
       "      <td>1610612759</td>\n",
       "      <td>1610612756</td>\n",
       "      <td>SAS</td>\n",
       "      <td>Spurs</td>\n",
       "      <td>PHX</td>\n",
       "      <td>Suns</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003-10-28</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.100</td>\n",
       "      <td>69.512195</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>91.475610</td>\n",
       "      <td>87.8</td>\n",
       "      <td>94.1</td>\n",
       "      <td>0.442159</td>\n",
       "      <td>0.4760</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>0.358293</td>\n",
       "      <td>0.2832</td>\n",
       "      <td>0.3390</td>\n",
       "      <td>20.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.500</td>\n",
       "      <td>35.365854</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>94.182927</td>\n",
       "      <td>94.2</td>\n",
       "      <td>94.9</td>\n",
       "      <td>0.444463</td>\n",
       "      <td>0.4424</td>\n",
       "      <td>0.4537</td>\n",
       "      <td>0.4537</td>\n",
       "      <td>0.340049</td>\n",
       "      <td>0.4792</td>\n",
       "      <td>0.3745</td>\n",
       "      <td>14.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20300003</td>\n",
       "      <td>1610612747</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>LAL</td>\n",
       "      <td>Lakers</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Mavericks</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003-10-28</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.350</td>\n",
       "      <td>68.292683</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>98.195122</td>\n",
       "      <td>96.4</td>\n",
       "      <td>95.9</td>\n",
       "      <td>0.454000</td>\n",
       "      <td>0.4402</td>\n",
       "      <td>0.4456</td>\n",
       "      <td>0.4456</td>\n",
       "      <td>0.321244</td>\n",
       "      <td>0.2542</td>\n",
       "      <td>0.3458</td>\n",
       "      <td>32.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.280</td>\n",
       "      <td>63.414634</td>\n",
       "      <td>60.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>105.195122</td>\n",
       "      <td>105.0</td>\n",
       "      <td>113.8</td>\n",
       "      <td>0.460732</td>\n",
       "      <td>0.4686</td>\n",
       "      <td>0.5147</td>\n",
       "      <td>0.5147</td>\n",
       "      <td>0.347183</td>\n",
       "      <td>0.3966</td>\n",
       "      <td>0.4257</td>\n",
       "      <td>17.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20300004</td>\n",
       "      <td>1610612738</td>\n",
       "      <td>1610612748</td>\n",
       "      <td>BOS</td>\n",
       "      <td>Celtics</td>\n",
       "      <td>MIA</td>\n",
       "      <td>Heat</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003-10-29</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.313</td>\n",
       "      <td>43.902439</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>95.256098</td>\n",
       "      <td>98.8</td>\n",
       "      <td>97.8</td>\n",
       "      <td>0.444085</td>\n",
       "      <td>0.4358</td>\n",
       "      <td>0.4562</td>\n",
       "      <td>0.4562</td>\n",
       "      <td>0.342012</td>\n",
       "      <td>0.3174</td>\n",
       "      <td>0.3233</td>\n",
       "      <td>28.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.417</td>\n",
       "      <td>51.219512</td>\n",
       "      <td>80.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>90.268293</td>\n",
       "      <td>94.0</td>\n",
       "      <td>93.6</td>\n",
       "      <td>0.426366</td>\n",
       "      <td>0.4210</td>\n",
       "      <td>0.4185</td>\n",
       "      <td>0.4185</td>\n",
       "      <td>0.358317</td>\n",
       "      <td>0.3632</td>\n",
       "      <td>0.3776</td>\n",
       "      <td>14.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20300005</td>\n",
       "      <td>1610612752</td>\n",
       "      <td>1610612753</td>\n",
       "      <td>NYK</td>\n",
       "      <td>Knicks</td>\n",
       "      <td>ORL</td>\n",
       "      <td>Magic</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003-10-29</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.313</td>\n",
       "      <td>47.560976</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>91.975610</td>\n",
       "      <td>95.0</td>\n",
       "      <td>92.9</td>\n",
       "      <td>0.443159</td>\n",
       "      <td>0.4526</td>\n",
       "      <td>0.4425</td>\n",
       "      <td>0.4425</td>\n",
       "      <td>0.358354</td>\n",
       "      <td>0.3594</td>\n",
       "      <td>0.3615</td>\n",
       "      <td>20.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.250</td>\n",
       "      <td>25.609756</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>94.036585</td>\n",
       "      <td>88.8</td>\n",
       "      <td>89.2</td>\n",
       "      <td>0.429646</td>\n",
       "      <td>0.4318</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.341780</td>\n",
       "      <td>0.2478</td>\n",
       "      <td>0.3035</td>\n",
       "      <td>17.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19393</th>\n",
       "      <td>21801226</td>\n",
       "      <td>1610612749</td>\n",
       "      <td>1610612760</td>\n",
       "      <td>MIL</td>\n",
       "      <td>Bucks</td>\n",
       "      <td>OKC</td>\n",
       "      <td>Thunder</td>\n",
       "      <td>2018</td>\n",
       "      <td>2019-04-10</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.326</td>\n",
       "      <td>73.170732</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>118.121951</td>\n",
       "      <td>123.6</td>\n",
       "      <td>123.2</td>\n",
       "      <td>0.476805</td>\n",
       "      <td>0.4758</td>\n",
       "      <td>0.4821</td>\n",
       "      <td>0.4821</td>\n",
       "      <td>0.353244</td>\n",
       "      <td>0.3388</td>\n",
       "      <td>0.3713</td>\n",
       "      <td>27.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.426</td>\n",
       "      <td>59.756098</td>\n",
       "      <td>100.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>114.475610</td>\n",
       "      <td>122.6</td>\n",
       "      <td>114.7</td>\n",
       "      <td>0.454854</td>\n",
       "      <td>0.4720</td>\n",
       "      <td>0.4530</td>\n",
       "      <td>0.4530</td>\n",
       "      <td>0.351329</td>\n",
       "      <td>0.3874</td>\n",
       "      <td>0.3648</td>\n",
       "      <td>40.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>116.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19394</th>\n",
       "      <td>21801227</td>\n",
       "      <td>1610612759</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>SAS</td>\n",
       "      <td>Spurs</td>\n",
       "      <td>DAL</td>\n",
       "      <td>Mavericks</td>\n",
       "      <td>2018</td>\n",
       "      <td>2019-04-10</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.333</td>\n",
       "      <td>58.536585</td>\n",
       "      <td>80.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>111.658537</td>\n",
       "      <td>109.6</td>\n",
       "      <td>110.6</td>\n",
       "      <td>0.479598</td>\n",
       "      <td>0.4916</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>0.4828</td>\n",
       "      <td>0.396671</td>\n",
       "      <td>0.3588</td>\n",
       "      <td>0.3472</td>\n",
       "      <td>22.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.297</td>\n",
       "      <td>40.243902</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>108.865854</td>\n",
       "      <td>112.6</td>\n",
       "      <td>113.7</td>\n",
       "      <td>0.447659</td>\n",
       "      <td>0.4402</td>\n",
       "      <td>0.4527</td>\n",
       "      <td>0.4527</td>\n",
       "      <td>0.341451</td>\n",
       "      <td>0.3062</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>27.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19395</th>\n",
       "      <td>21801228</td>\n",
       "      <td>1610612743</td>\n",
       "      <td>1610612750</td>\n",
       "      <td>DEN</td>\n",
       "      <td>Nuggets</td>\n",
       "      <td>MIN</td>\n",
       "      <td>Timberwolves</td>\n",
       "      <td>2018</td>\n",
       "      <td>2019-04-10</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.303</td>\n",
       "      <td>65.853659</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>110.670732</td>\n",
       "      <td>109.4</td>\n",
       "      <td>103.4</td>\n",
       "      <td>0.466951</td>\n",
       "      <td>0.4816</td>\n",
       "      <td>0.4518</td>\n",
       "      <td>0.4518</td>\n",
       "      <td>0.349707</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>23.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.406</td>\n",
       "      <td>43.902439</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>112.475610</td>\n",
       "      <td>108.4</td>\n",
       "      <td>112.7</td>\n",
       "      <td>0.457207</td>\n",
       "      <td>0.4752</td>\n",
       "      <td>0.4674</td>\n",
       "      <td>0.4674</td>\n",
       "      <td>0.355329</td>\n",
       "      <td>0.3708</td>\n",
       "      <td>0.3819</td>\n",
       "      <td>24.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19396</th>\n",
       "      <td>21801229</td>\n",
       "      <td>1610612746</td>\n",
       "      <td>1610612762</td>\n",
       "      <td>LAC</td>\n",
       "      <td>Clippers</td>\n",
       "      <td>UTA</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>2018</td>\n",
       "      <td>2019-04-10</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.429</td>\n",
       "      <td>58.536585</td>\n",
       "      <td>40.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>115.146341</td>\n",
       "      <td>116.0</td>\n",
       "      <td>118.6</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>0.4746</td>\n",
       "      <td>0.4949</td>\n",
       "      <td>0.4949</td>\n",
       "      <td>0.387537</td>\n",
       "      <td>0.3734</td>\n",
       "      <td>0.3997</td>\n",
       "      <td>34.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.400</td>\n",
       "      <td>60.975610</td>\n",
       "      <td>60.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>111.719512</td>\n",
       "      <td>120.2</td>\n",
       "      <td>119.4</td>\n",
       "      <td>0.468500</td>\n",
       "      <td>0.5020</td>\n",
       "      <td>0.5079</td>\n",
       "      <td>0.5079</td>\n",
       "      <td>0.354500</td>\n",
       "      <td>0.4070</td>\n",
       "      <td>0.4035</td>\n",
       "      <td>31.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19397</th>\n",
       "      <td>21801230</td>\n",
       "      <td>1610612757</td>\n",
       "      <td>1610612758</td>\n",
       "      <td>POR</td>\n",
       "      <td>Trail Blazers</td>\n",
       "      <td>SAC</td>\n",
       "      <td>Kings</td>\n",
       "      <td>2018</td>\n",
       "      <td>2019-04-10</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.583</td>\n",
       "      <td>64.634146</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>114.658537</td>\n",
       "      <td>116.2</td>\n",
       "      <td>118.7</td>\n",
       "      <td>0.469024</td>\n",
       "      <td>0.4906</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.362110</td>\n",
       "      <td>0.3738</td>\n",
       "      <td>0.3495</td>\n",
       "      <td>19.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.419</td>\n",
       "      <td>47.560976</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>114.182927</td>\n",
       "      <td>116.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.464305</td>\n",
       "      <td>0.4660</td>\n",
       "      <td>0.4634</td>\n",
       "      <td>0.4634</td>\n",
       "      <td>0.376780</td>\n",
       "      <td>0.3458</td>\n",
       "      <td>0.3980</td>\n",
       "      <td>25.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19398 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        GAME_ID  HOME_TEAM_ID  VISITOR_TEAM_ID HOME_TEAM_ABBREVIATION  \\\n",
       "0      20300001    1610612755       1610612748                    PHI   \n",
       "1      20300002    1610612759       1610612756                    SAS   \n",
       "2      20300003    1610612747       1610612742                    LAL   \n",
       "3      20300004    1610612738       1610612748                    BOS   \n",
       "4      20300005    1610612752       1610612753                    NYK   \n",
       "...         ...           ...              ...                    ...   \n",
       "19393  21801226    1610612749       1610612760                    MIL   \n",
       "19394  21801227    1610612759       1610612742                    SAS   \n",
       "19395  21801228    1610612743       1610612750                    DEN   \n",
       "19396  21801229    1610612746       1610612762                    LAC   \n",
       "19397  21801230    1610612757       1610612758                    POR   \n",
       "\n",
       "      HOME_TEAM_NICKNAME VISITOR_TEAM_ABBREVIATION VISITOR_TEAM_NICKNAME  \\\n",
       "0                  76ers                       MIA                  Heat   \n",
       "1                  Spurs                       PHX                  Suns   \n",
       "2                 Lakers                       DAL             Mavericks   \n",
       "3                Celtics                       MIA                  Heat   \n",
       "4                 Knicks                       ORL                 Magic   \n",
       "...                  ...                       ...                   ...   \n",
       "19393              Bucks                       OKC               Thunder   \n",
       "19394              Spurs                       DAL             Mavericks   \n",
       "19395            Nuggets                       MIN          Timberwolves   \n",
       "19396           Clippers                       UTA                  Jazz   \n",
       "19397      Trail Blazers                       SAC                 Kings   \n",
       "\n",
       "       SEASON   GAME_DATE  FG_PCT_home  FT_PCT_home  FG3_PCT_home  \\\n",
       "0        2003  2003-10-28        0.440        0.533         0.350   \n",
       "1        2003  2003-10-28        0.425        0.769         0.100   \n",
       "2        2003  2003-10-28        0.506        0.600         0.350   \n",
       "3        2003  2003-10-29        0.507        0.731         0.313   \n",
       "4        2003  2003-10-29        0.400        0.824         0.313   \n",
       "...       ...         ...          ...          ...           ...   \n",
       "19393    2018  2019-04-10        0.430        0.714         0.326   \n",
       "19394    2018  2019-04-10        0.466        0.833         0.333   \n",
       "19395    2018  2019-04-10        0.448        0.647         0.303   \n",
       "19396    2018  2019-04-10        0.509        0.767         0.429   \n",
       "19397    2018  2019-04-10        0.582        0.727         0.583   \n",
       "\n",
       "       PERCENT_VIC_UNITL_THIS_GAME_HOME_TEAM  \\\n",
       "0                                  40.243902   \n",
       "1                                  69.512195   \n",
       "2                                  68.292683   \n",
       "3                                  43.902439   \n",
       "4                                  47.560976   \n",
       "...                                      ...   \n",
       "19393                              73.170732   \n",
       "19394                              58.536585   \n",
       "19395                              65.853659   \n",
       "19396                              58.536585   \n",
       "19397                              64.634146   \n",
       "\n",
       "       PERCENT_VIC_LAST5_GAMES_HOME_TEAM  PERCENT_VIC_LAST10_GAMES_HOME_TEAM  \\\n",
       "0                                   20.0                                30.0   \n",
       "1                                  100.0                               100.0   \n",
       "2                                   60.0                                70.0   \n",
       "3                                   20.0                                40.0   \n",
       "4                                   60.0                                60.0   \n",
       "...                                  ...                                 ...   \n",
       "19393                               60.0                                70.0   \n",
       "19394                               80.0                                60.0   \n",
       "19395                               60.0                                50.0   \n",
       "19396                               40.0                                60.0   \n",
       "19397                               80.0                                80.0   \n",
       "\n",
       "       AVG_POINTS_UNTIL_THIS_GAME_HOME_TEAM  AVG_POINTS_LAST5_HOME_TEAM  \\\n",
       "0                                 87.987805                        88.0   \n",
       "1                                 91.475610                        87.8   \n",
       "2                                 98.195122                        96.4   \n",
       "3                                 95.256098                        98.8   \n",
       "4                                 91.975610                        95.0   \n",
       "...                                     ...                         ...   \n",
       "19393                            118.121951                       123.6   \n",
       "19394                            111.658537                       109.6   \n",
       "19395                            110.670732                       109.4   \n",
       "19396                            115.146341                       116.0   \n",
       "19397                            114.658537                       116.2   \n",
       "\n",
       "       AVG_POINTS_LAST10_HOME_TEAM  AVG_FGPERCENT_UNTIL_THIS_GAME_HOME_TEAM  \\\n",
       "0                             84.3                                 0.429683   \n",
       "1                             94.1                                 0.442159   \n",
       "2                             95.9                                 0.454000   \n",
       "3                             97.8                                 0.444085   \n",
       "4                             92.9                                 0.443159   \n",
       "...                            ...                                      ...   \n",
       "19393                        123.2                                 0.476805   \n",
       "19394                        110.6                                 0.479598   \n",
       "19395                        103.4                                 0.466951   \n",
       "19396                        118.6                                 0.472000   \n",
       "19397                        118.7                                 0.469024   \n",
       "\n",
       "       AVG_FGPERCENT_LAST5_HOME_TEAM  AVG_FGPERCENT_LAST10_HOME_TEAM  \\\n",
       "0                             0.4656                          0.4251   \n",
       "1                             0.4760                          0.4828   \n",
       "2                             0.4402                          0.4456   \n",
       "3                             0.4358                          0.4562   \n",
       "4                             0.4526                          0.4425   \n",
       "...                              ...                             ...   \n",
       "19393                         0.4758                          0.4821   \n",
       "19394                         0.4916                          0.4828   \n",
       "19395                         0.4816                          0.4518   \n",
       "19396                         0.4746                          0.4949   \n",
       "19397                         0.4906                          0.4800   \n",
       "\n",
       "       AVG_FGPERCENT_LAST10_HOME_TEAM.1  AVG_FG3PCT_UNTIL_THIS_GAME_HOME_TEAM  \\\n",
       "0                                0.4251                              0.335171   \n",
       "1                                0.4828                              0.358293   \n",
       "2                                0.4456                              0.321244   \n",
       "3                                0.4562                              0.342012   \n",
       "4                                0.4425                              0.358354   \n",
       "...                                 ...                                   ...   \n",
       "19393                            0.4821                              0.353244   \n",
       "19394                            0.4828                              0.396671   \n",
       "19395                            0.4518                              0.349707   \n",
       "19396                            0.4949                              0.387537   \n",
       "19397                            0.4800                              0.362110   \n",
       "\n",
       "       AVG_FG3PCT_LAST5_HOME_TEAM  AVG_FG3PCT_LAST10_HOME_TEAM  AST_home  \\\n",
       "0                          0.2914                       0.3069      25.0   \n",
       "1                          0.2832                       0.3390      20.0   \n",
       "2                          0.2542                       0.3458      32.0   \n",
       "3                          0.3174                       0.3233      28.0   \n",
       "4                          0.3594                       0.3615      20.0   \n",
       "...                           ...                          ...       ...   \n",
       "19393                      0.3388                       0.3713      27.0   \n",
       "19394                      0.3588                       0.3472      22.0   \n",
       "19395                      0.3600                       0.3077      23.0   \n",
       "19396                      0.3734                       0.3997      34.0   \n",
       "19397                      0.3738                       0.3495      19.0   \n",
       "\n",
       "       REB_home  FG_PCT_away  FT_PCT_away  FG3_PCT_away  \\\n",
       "0          39.0        0.408        0.824         0.250   \n",
       "1          38.0        0.361        0.810         0.500   \n",
       "2          46.0        0.376        0.733         0.280   \n",
       "3          40.0        0.366        0.750         0.417   \n",
       "4          48.0        0.368        0.552         0.250   \n",
       "...         ...          ...          ...           ...   \n",
       "19393      53.0        0.485        0.615         0.426   \n",
       "19394      53.0        0.407        0.750         0.297   \n",
       "19395      53.0        0.429        0.667         0.406   \n",
       "19396      52.0        0.443        0.879         0.400   \n",
       "19397      44.0        0.521        0.813         0.419   \n",
       "\n",
       "       PERCENT_VIC_UNITL_THIS_GAME_VISITOR_TEAM  \\\n",
       "0                                     51.219512   \n",
       "1                                     35.365854   \n",
       "2                                     63.414634   \n",
       "3                                     51.219512   \n",
       "4                                     25.609756   \n",
       "...                                         ...   \n",
       "19393                                 59.756098   \n",
       "19394                                 40.243902   \n",
       "19395                                 43.902439   \n",
       "19396                                 60.975610   \n",
       "19397                                 47.560976   \n",
       "\n",
       "       PERCENT_VIC_LAST5_GAMES_VISITOR_TEAM  \\\n",
       "0                                      80.0   \n",
       "1                                      60.0   \n",
       "2                                      60.0   \n",
       "3                                      80.0   \n",
       "4                                      40.0   \n",
       "...                                     ...   \n",
       "19393                                 100.0   \n",
       "19394                                  40.0   \n",
       "19395                                  40.0   \n",
       "19396                                  60.0   \n",
       "19397                                  20.0   \n",
       "\n",
       "       PERCENT_VIC_LAST10_GAMES_VISITOR_TEAM  \\\n",
       "0                                       70.0   \n",
       "1                                       50.0   \n",
       "2                                       80.0   \n",
       "3                                       70.0   \n",
       "4                                       20.0   \n",
       "...                                      ...   \n",
       "19393                                   70.0   \n",
       "19394                                   50.0   \n",
       "19395                                   40.0   \n",
       "19396                                   80.0   \n",
       "19397                                   30.0   \n",
       "\n",
       "       AVG_POINTS_UNTIL_THIS_GAME_VISITOR_TEAM  AVG_POINTS_LAST5_VISITOR_TEAM  \\\n",
       "0                                    90.268293                           94.0   \n",
       "1                                    94.182927                           94.2   \n",
       "2                                   105.195122                          105.0   \n",
       "3                                    90.268293                           94.0   \n",
       "4                                    94.036585                           88.8   \n",
       "...                                        ...                            ...   \n",
       "19393                               114.475610                          122.6   \n",
       "19394                               108.865854                          112.6   \n",
       "19395                               112.475610                          108.4   \n",
       "19396                               111.719512                          120.2   \n",
       "19397                               114.182927                          116.0   \n",
       "\n",
       "       AVG_POINTS_LAST10_VISITOR_TEAM  \\\n",
       "0                                93.6   \n",
       "1                                94.9   \n",
       "2                               113.8   \n",
       "3                                93.6   \n",
       "4                                89.2   \n",
       "...                               ...   \n",
       "19393                           114.7   \n",
       "19394                           113.7   \n",
       "19395                           112.7   \n",
       "19396                           119.4   \n",
       "19397                           115.0   \n",
       "\n",
       "       AVG_FGPERCENT_UNTIL_THIS_GAME_VISITOR_TEAM  \\\n",
       "0                                        0.426366   \n",
       "1                                        0.444463   \n",
       "2                                        0.460732   \n",
       "3                                        0.426366   \n",
       "4                                        0.429646   \n",
       "...                                           ...   \n",
       "19393                                    0.454854   \n",
       "19394                                    0.447659   \n",
       "19395                                    0.457207   \n",
       "19396                                    0.468500   \n",
       "19397                                    0.464305   \n",
       "\n",
       "       AVG_FGPERCENT_LAST5_VISITOR_TEAM  AVG_FGPERCENT_LAST10_VISITOR_TEAM  \\\n",
       "0                                0.4210                             0.4185   \n",
       "1                                0.4424                             0.4537   \n",
       "2                                0.4686                             0.5147   \n",
       "3                                0.4210                             0.4185   \n",
       "4                                0.4318                             0.4200   \n",
       "...                                 ...                                ...   \n",
       "19393                            0.4720                             0.4530   \n",
       "19394                            0.4402                             0.4527   \n",
       "19395                            0.4752                             0.4674   \n",
       "19396                            0.5020                             0.5079   \n",
       "19397                            0.4660                             0.4634   \n",
       "\n",
       "       AVG_FGPERCENT_LAST10_VISITOR_TEAM.1  \\\n",
       "0                                   0.4185   \n",
       "1                                   0.4537   \n",
       "2                                   0.5147   \n",
       "3                                   0.4185   \n",
       "4                                   0.4200   \n",
       "...                                    ...   \n",
       "19393                               0.4530   \n",
       "19394                               0.4527   \n",
       "19395                               0.4674   \n",
       "19396                               0.5079   \n",
       "19397                               0.4634   \n",
       "\n",
       "       AVG_FG3PCT_UNTIL_THIS_GAME_VISITOR_TEAM  AVG_FG3PCT_LAST5_VISITOR_TEAM  \\\n",
       "0                                     0.358317                         0.3632   \n",
       "1                                     0.340049                         0.4792   \n",
       "2                                     0.347183                         0.3966   \n",
       "3                                     0.358317                         0.3632   \n",
       "4                                     0.341780                         0.2478   \n",
       "...                                        ...                            ...   \n",
       "19393                                 0.351329                         0.3874   \n",
       "19394                                 0.341451                         0.3062   \n",
       "19395                                 0.355329                         0.3708   \n",
       "19396                                 0.354500                         0.4070   \n",
       "19397                                 0.376780                         0.3458   \n",
       "\n",
       "       AVG_FG3PCT_LAST10_VISITOR_TEAM  AST_away  REB_away  HOME_TEAM_WINS  \\\n",
       "0                              0.3776      16.0      44.0               1   \n",
       "1                              0.3745      14.0      43.0               1   \n",
       "2                              0.4257      17.0      46.0               1   \n",
       "3                              0.3776      14.0      39.0               1   \n",
       "4                              0.3035      17.0      44.0               0   \n",
       "...                               ...       ...       ...             ...   \n",
       "19393                          0.3648      40.0      53.0               0   \n",
       "19394                          0.3372      27.0      42.0               1   \n",
       "19395                          0.3819      24.0      41.0               1   \n",
       "19396                          0.4035      31.0      57.0               1   \n",
       "19397                          0.3980      25.0      35.0               1   \n",
       "\n",
       "       VISITOR_TEAM_WINS  PTS_home  PTS_away  \n",
       "0                      0      89.0      74.0  \n",
       "1                      0      83.0      82.0  \n",
       "2                      0     109.0      93.0  \n",
       "3                      0      98.0      75.0  \n",
       "4                      1      83.0      85.0  \n",
       "...                  ...       ...       ...  \n",
       "19393                  1     116.0     127.0  \n",
       "19394                  0     105.0      94.0  \n",
       "19395                  0      99.0      95.0  \n",
       "19396                  0     143.0     137.0  \n",
       "19397                  0     136.0     131.0  \n",
       "\n",
       "[19398 rows x 49 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns = None\n",
    "df = pd.read_csv('df_complete.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "20c26c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score, roc_curve, f1_score, \\\n",
    "precision_score, recall_score, accuracy_score, precision_recall_curve, auc\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold, RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1bf7e65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,9:44].values\n",
    "y = df.iloc[:,45].values\n",
    "y=y.astype('int')\n",
    "\n",
    "X_copy = X.copy()\n",
    "X_norm = (X_copy - X_copy.mean()) / X_copy.std()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aa0365",
   "metadata": {},
   "source": [
    "# Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037df4e5",
   "metadata": {},
   "source": [
    "### Default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "76cde5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% de acierto: \n",
      "0.7847422680412371\n",
      "Matrix Confusion: \n",
      "[[1482  477]\n",
      " [ 567 2324]]\n",
      "Clasification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74      1959\n",
      "           1       0.83      0.80      0.82      2891\n",
      "\n",
      "    accuracy                           0.78      4850\n",
      "   macro avg       0.78      0.78      0.78      4850\n",
      "weighted avg       0.79      0.78      0.79      4850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.25, random_state=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "print(\"% de acierto: \")\n",
    "print(np.mean(y_pred == y_test))\n",
    "print(\"Matrix Confusion: \")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"Clasification report: \")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d1802b",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "910157d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Mejores hiperparámetros encontrados (cv)\n",
      "----------------------------------------\n",
      "{'var_smoothing': 1e-08} : 0.7824901587166582 accuracy\n",
      "----------------------------------------\n",
      "% de acierto: \n",
      "0.7847422680412371\n",
      "----------------------------------------\n",
      "Matrix Confusion: \n",
      "[[1482  477]\n",
      " [ 567 2324]]\n",
      "----------------------------------------\n",
      "Clasification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74      1959\n",
      "           1       0.83      0.80      0.82      2891\n",
      "\n",
      "    accuracy                           0.78      4850\n",
      "   macro avg       0.78      0.78      0.78      4850\n",
      "weighted avg       0.79      0.78      0.79      4850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.25, random_state=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Grid de hiperparámetros evaluados\n",
    "# ==============================================================================\n",
    "param_grid = {'var_smoothing' : [0.00000001, 0.000000001, 0.0000000001, 0.00000000001]\n",
    "             }\n",
    "\n",
    "# Búsqueda por grid search con validación cruzada\n",
    "# ==============================================================================\n",
    "grid = GridSearchCV(\n",
    "        estimator  = GaussianNB(),\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'accuracy',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123), \n",
    "        refit      = True,\n",
    "        verbose    = 0,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "grid.fit(X = X_train, y = y_train)\n",
    "\n",
    "# Resultados\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(grid.cv_results_)\n",
    "resultados.filter(regex = '(param*|mean_t|std_t)') \\\n",
    "    .drop(columns = 'params') \\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)\n",
    "\n",
    "\n",
    "\n",
    "# Mejores hiperparámetros por validación cruzada\n",
    "# ==============================================================================\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Mejores hiperparámetros encontrados (cv)\")\n",
    "print(\"----------------------------------------\")\n",
    "print(grid.best_params_, \":\", grid.best_score_, grid.scoring)\n",
    "print(\"----------------------------------------\")\n",
    "\n",
    "\n",
    "modelo_final = grid.best_estimator_\n",
    "y_pred = modelo_final.predict(X_test)\n",
    "\n",
    "print(\"% de acierto: \")\n",
    "print(np.mean(y_pred == y_test))\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Matrix Confusion: \")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Clasification report: \")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6f32ef0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 1e-08}\n",
      "0.7824901587166582\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "648450b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_var_smoothing</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>split10_train_score</th>\n",
       "      <th>split11_train_score</th>\n",
       "      <th>split12_train_score</th>\n",
       "      <th>split13_train_score</th>\n",
       "      <th>split14_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.019217</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'var_smoothing': 1e-08}</td>\n",
       "      <td>0.785911</td>\n",
       "      <td>0.782131</td>\n",
       "      <td>0.767354</td>\n",
       "      <td>0.777931</td>\n",
       "      <td>0.795806</td>\n",
       "      <td>0.782474</td>\n",
       "      <td>0.787285</td>\n",
       "      <td>0.784536</td>\n",
       "      <td>0.780681</td>\n",
       "      <td>0.777587</td>\n",
       "      <td>0.787629</td>\n",
       "      <td>0.789003</td>\n",
       "      <td>0.775601</td>\n",
       "      <td>0.784462</td>\n",
       "      <td>0.778962</td>\n",
       "      <td>0.78249</td>\n",
       "      <td>0.006461</td>\n",
       "      <td>1</td>\n",
       "      <td>0.782265</td>\n",
       "      <td>0.782351</td>\n",
       "      <td>0.785358</td>\n",
       "      <td>0.783658</td>\n",
       "      <td>0.78194</td>\n",
       "      <td>0.782866</td>\n",
       "      <td>0.782351</td>\n",
       "      <td>0.784069</td>\n",
       "      <td>0.784174</td>\n",
       "      <td>0.78194</td>\n",
       "      <td>0.781406</td>\n",
       "      <td>0.781234</td>\n",
       "      <td>0.783984</td>\n",
       "      <td>0.784088</td>\n",
       "      <td>0.783315</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.001157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016472</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'var_smoothing': 1e-09}</td>\n",
       "      <td>0.785911</td>\n",
       "      <td>0.782131</td>\n",
       "      <td>0.767354</td>\n",
       "      <td>0.777931</td>\n",
       "      <td>0.795806</td>\n",
       "      <td>0.782474</td>\n",
       "      <td>0.787285</td>\n",
       "      <td>0.784536</td>\n",
       "      <td>0.780681</td>\n",
       "      <td>0.777587</td>\n",
       "      <td>0.787629</td>\n",
       "      <td>0.789003</td>\n",
       "      <td>0.775601</td>\n",
       "      <td>0.784462</td>\n",
       "      <td>0.778962</td>\n",
       "      <td>0.78249</td>\n",
       "      <td>0.006461</td>\n",
       "      <td>1</td>\n",
       "      <td>0.782265</td>\n",
       "      <td>0.782351</td>\n",
       "      <td>0.785358</td>\n",
       "      <td>0.783658</td>\n",
       "      <td>0.78194</td>\n",
       "      <td>0.782866</td>\n",
       "      <td>0.782351</td>\n",
       "      <td>0.784069</td>\n",
       "      <td>0.784174</td>\n",
       "      <td>0.78194</td>\n",
       "      <td>0.781406</td>\n",
       "      <td>0.781234</td>\n",
       "      <td>0.783984</td>\n",
       "      <td>0.784088</td>\n",
       "      <td>0.783315</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.001157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016730</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'var_smoothing': 1e-10}</td>\n",
       "      <td>0.785911</td>\n",
       "      <td>0.782131</td>\n",
       "      <td>0.767354</td>\n",
       "      <td>0.777931</td>\n",
       "      <td>0.795806</td>\n",
       "      <td>0.782474</td>\n",
       "      <td>0.787285</td>\n",
       "      <td>0.784536</td>\n",
       "      <td>0.780681</td>\n",
       "      <td>0.777587</td>\n",
       "      <td>0.787629</td>\n",
       "      <td>0.789003</td>\n",
       "      <td>0.775601</td>\n",
       "      <td>0.784462</td>\n",
       "      <td>0.778962</td>\n",
       "      <td>0.78249</td>\n",
       "      <td>0.006461</td>\n",
       "      <td>1</td>\n",
       "      <td>0.782265</td>\n",
       "      <td>0.782351</td>\n",
       "      <td>0.785358</td>\n",
       "      <td>0.783658</td>\n",
       "      <td>0.78194</td>\n",
       "      <td>0.782866</td>\n",
       "      <td>0.782351</td>\n",
       "      <td>0.784069</td>\n",
       "      <td>0.784174</td>\n",
       "      <td>0.78194</td>\n",
       "      <td>0.781406</td>\n",
       "      <td>0.781234</td>\n",
       "      <td>0.783984</td>\n",
       "      <td>0.784088</td>\n",
       "      <td>0.783315</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.001157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017173</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'var_smoothing': 1e-11}</td>\n",
       "      <td>0.785911</td>\n",
       "      <td>0.782131</td>\n",
       "      <td>0.767354</td>\n",
       "      <td>0.777931</td>\n",
       "      <td>0.795806</td>\n",
       "      <td>0.782474</td>\n",
       "      <td>0.787285</td>\n",
       "      <td>0.784536</td>\n",
       "      <td>0.780681</td>\n",
       "      <td>0.777587</td>\n",
       "      <td>0.787629</td>\n",
       "      <td>0.789003</td>\n",
       "      <td>0.775601</td>\n",
       "      <td>0.784462</td>\n",
       "      <td>0.778962</td>\n",
       "      <td>0.78249</td>\n",
       "      <td>0.006461</td>\n",
       "      <td>1</td>\n",
       "      <td>0.782265</td>\n",
       "      <td>0.782351</td>\n",
       "      <td>0.785358</td>\n",
       "      <td>0.783658</td>\n",
       "      <td>0.78194</td>\n",
       "      <td>0.782866</td>\n",
       "      <td>0.782351</td>\n",
       "      <td>0.784069</td>\n",
       "      <td>0.784174</td>\n",
       "      <td>0.78194</td>\n",
       "      <td>0.781406</td>\n",
       "      <td>0.781234</td>\n",
       "      <td>0.783984</td>\n",
       "      <td>0.784088</td>\n",
       "      <td>0.783315</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.001157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.019217      0.001887         0.004045        0.000780   \n",
       "1       0.016472      0.001229         0.003465        0.000418   \n",
       "2       0.016730      0.001767         0.003443        0.000345   \n",
       "3       0.017173      0.001582         0.003632        0.000673   \n",
       "\n",
       "  param_var_smoothing                    params  split0_test_score  \\\n",
       "0                 0.0  {'var_smoothing': 1e-08}           0.785911   \n",
       "1                 0.0  {'var_smoothing': 1e-09}           0.785911   \n",
       "2                 0.0  {'var_smoothing': 1e-10}           0.785911   \n",
       "3                 0.0  {'var_smoothing': 1e-11}           0.785911   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.782131           0.767354           0.777931           0.795806   \n",
       "1           0.782131           0.767354           0.777931           0.795806   \n",
       "2           0.782131           0.767354           0.777931           0.795806   \n",
       "3           0.782131           0.767354           0.777931           0.795806   \n",
       "\n",
       "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0           0.782474           0.787285           0.784536           0.780681   \n",
       "1           0.782474           0.787285           0.784536           0.780681   \n",
       "2           0.782474           0.787285           0.784536           0.780681   \n",
       "3           0.782474           0.787285           0.784536           0.780681   \n",
       "\n",
       "   split9_test_score  split10_test_score  split11_test_score  \\\n",
       "0           0.777587            0.787629            0.789003   \n",
       "1           0.777587            0.787629            0.789003   \n",
       "2           0.777587            0.787629            0.789003   \n",
       "3           0.777587            0.787629            0.789003   \n",
       "\n",
       "   split12_test_score  split13_test_score  split14_test_score  \\\n",
       "0            0.775601            0.784462            0.778962   \n",
       "1            0.775601            0.784462            0.778962   \n",
       "2            0.775601            0.784462            0.778962   \n",
       "3            0.775601            0.784462            0.778962   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0          0.78249        0.006461                1            0.782265   \n",
       "1          0.78249        0.006461                1            0.782265   \n",
       "2          0.78249        0.006461                1            0.782265   \n",
       "3          0.78249        0.006461                1            0.782265   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.782351            0.785358            0.783658   \n",
       "1            0.782351            0.785358            0.783658   \n",
       "2            0.782351            0.785358            0.783658   \n",
       "3            0.782351            0.785358            0.783658   \n",
       "\n",
       "   split4_train_score  split5_train_score  split6_train_score  \\\n",
       "0             0.78194            0.782866            0.782351   \n",
       "1             0.78194            0.782866            0.782351   \n",
       "2             0.78194            0.782866            0.782351   \n",
       "3             0.78194            0.782866            0.782351   \n",
       "\n",
       "   split7_train_score  split8_train_score  split9_train_score  \\\n",
       "0            0.784069            0.784174             0.78194   \n",
       "1            0.784069            0.784174             0.78194   \n",
       "2            0.784069            0.784174             0.78194   \n",
       "3            0.784069            0.784174             0.78194   \n",
       "\n",
       "   split10_train_score  split11_train_score  split12_train_score  \\\n",
       "0             0.781406             0.781234             0.783984   \n",
       "1             0.781406             0.781234             0.783984   \n",
       "2             0.781406             0.781234             0.783984   \n",
       "3             0.781406             0.781234             0.783984   \n",
       "\n",
       "   split13_train_score  split14_train_score  mean_train_score  std_train_score  \n",
       "0             0.784088             0.783315             0.783         0.001157  \n",
       "1             0.784088             0.783315             0.783         0.001157  \n",
       "2             0.784088             0.783315             0.783         0.001157  \n",
       "3             0.784088             0.783315             0.783         0.001157  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6498de",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f90926",
   "metadata": {},
   "source": [
    "### Default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dee88411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% de acierto: \n",
      "0.8595876288659794\n",
      "Matrix Confusion: \n",
      "[[1600  359]\n",
      " [ 322 2569]]\n",
      "Clasification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82      1959\n",
      "           1       0.88      0.89      0.88      2891\n",
      "\n",
      "    accuracy                           0.86      4850\n",
      "   macro avg       0.85      0.85      0.85      4850\n",
      "weighted avg       0.86      0.86      0.86      4850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.25, random_state=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "logr = LogisticRegression()\n",
    "logr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logr.predict(X_test)\n",
    "\n",
    "print(\"% de acierto: \")\n",
    "print(np.mean(y_pred == y_test))\n",
    "print(\"Matrix Confusion: \")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"Clasification report: \")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7212843",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d8f81f7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3874/4193696721.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m        )\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Resultados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.25, random_state=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Grid de hiperparámetros evaluados\n",
    "# ==============================================================================\n",
    "param_grid = {'C' : np.logspace(-4, 4, 50),\n",
    "              'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "             }\n",
    "\n",
    "# Búsqueda por grid search con validación cruzada\n",
    "# ==============================================================================\n",
    "grid = GridSearchCV(\n",
    "        estimator  = LogisticRegression(max_iter=500),\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'accuracy',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123), \n",
    "        refit      = True,\n",
    "        verbose    = 0,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "grid.fit(X = X_train, y = y_train)\n",
    "\n",
    "# Resultados\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(grid.cv_results_)\n",
    "resultados.filter(regex = '(param*|mean_t|std_t)') \\\n",
    "    .drop(columns = 'params') \\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)\n",
    "\n",
    "\n",
    "\n",
    "# Mejores hiperparámetros por validación cruzada\n",
    "# ==============================================================================\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Mejores hiperparámetros encontrados (cv)\")\n",
    "print(\"----------------------------------------\")\n",
    "print(grid.best_params_, \":\", grid.best_score_, grid.scoring)\n",
    "print(\"----------------------------------------\")\n",
    "\n",
    "\n",
    "modelo_final = grid.best_estimator_\n",
    "y_pred = modelo_final.predict(X_test)\n",
    "\n",
    "print(\"% de acierto: \")\n",
    "print(np.mean(y_pred == y_test))\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Matrix Confusion: \")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Clasification report: \")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "34bd49aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>split10_train_score</th>\n",
       "      <th>split11_train_score</th>\n",
       "      <th>split12_train_score</th>\n",
       "      <th>split13_train_score</th>\n",
       "      <th>split14_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.221485</td>\n",
       "      <td>0.104977</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.002543</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.0001, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.802405</td>\n",
       "      <td>0.795876</td>\n",
       "      <td>0.775945</td>\n",
       "      <td>0.798900</td>\n",
       "      <td>0.807838</td>\n",
       "      <td>0.793127</td>\n",
       "      <td>0.803093</td>\n",
       "      <td>0.800344</td>\n",
       "      <td>0.789618</td>\n",
       "      <td>0.797181</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.801718</td>\n",
       "      <td>0.795533</td>\n",
       "      <td>0.796837</td>\n",
       "      <td>0.790650</td>\n",
       "      <td>0.796604</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>248</td>\n",
       "      <td>0.796872</td>\n",
       "      <td>0.799880</td>\n",
       "      <td>0.796529</td>\n",
       "      <td>0.794570</td>\n",
       "      <td>0.798093</td>\n",
       "      <td>0.797474</td>\n",
       "      <td>0.797388</td>\n",
       "      <td>0.798505</td>\n",
       "      <td>0.796202</td>\n",
       "      <td>0.796288</td>\n",
       "      <td>0.797388</td>\n",
       "      <td>0.796357</td>\n",
       "      <td>0.796615</td>\n",
       "      <td>0.797577</td>\n",
       "      <td>0.795773</td>\n",
       "      <td>0.797034</td>\n",
       "      <td>0.001210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.037484</td>\n",
       "      <td>0.022329</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.0001, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.802405</td>\n",
       "      <td>0.795876</td>\n",
       "      <td>0.775945</td>\n",
       "      <td>0.798900</td>\n",
       "      <td>0.807838</td>\n",
       "      <td>0.793127</td>\n",
       "      <td>0.803093</td>\n",
       "      <td>0.800344</td>\n",
       "      <td>0.789618</td>\n",
       "      <td>0.797181</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.801718</td>\n",
       "      <td>0.795533</td>\n",
       "      <td>0.796837</td>\n",
       "      <td>0.790650</td>\n",
       "      <td>0.796604</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>248</td>\n",
       "      <td>0.796872</td>\n",
       "      <td>0.799966</td>\n",
       "      <td>0.796529</td>\n",
       "      <td>0.794570</td>\n",
       "      <td>0.798093</td>\n",
       "      <td>0.797474</td>\n",
       "      <td>0.797388</td>\n",
       "      <td>0.798505</td>\n",
       "      <td>0.796202</td>\n",
       "      <td>0.796288</td>\n",
       "      <td>0.797388</td>\n",
       "      <td>0.796357</td>\n",
       "      <td>0.796615</td>\n",
       "      <td>0.797577</td>\n",
       "      <td>0.795773</td>\n",
       "      <td>0.797040</td>\n",
       "      <td>0.001223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.046164</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.0001, 'solver': 'liblinear'}</td>\n",
       "      <td>0.814777</td>\n",
       "      <td>0.812715</td>\n",
       "      <td>0.808935</td>\n",
       "      <td>0.817807</td>\n",
       "      <td>0.829838</td>\n",
       "      <td>0.813402</td>\n",
       "      <td>0.818900</td>\n",
       "      <td>0.818557</td>\n",
       "      <td>0.812650</td>\n",
       "      <td>0.823651</td>\n",
       "      <td>0.823024</td>\n",
       "      <td>0.822680</td>\n",
       "      <td>0.817526</td>\n",
       "      <td>0.814713</td>\n",
       "      <td>0.810244</td>\n",
       "      <td>0.817295</td>\n",
       "      <td>0.005504</td>\n",
       "      <td>242</td>\n",
       "      <td>0.819385</td>\n",
       "      <td>0.818010</td>\n",
       "      <td>0.819471</td>\n",
       "      <td>0.818455</td>\n",
       "      <td>0.815792</td>\n",
       "      <td>0.818440</td>\n",
       "      <td>0.818611</td>\n",
       "      <td>0.819213</td>\n",
       "      <td>0.818455</td>\n",
       "      <td>0.813042</td>\n",
       "      <td>0.815174</td>\n",
       "      <td>0.815003</td>\n",
       "      <td>0.818268</td>\n",
       "      <td>0.820088</td>\n",
       "      <td>0.818627</td>\n",
       "      <td>0.817736</td>\n",
       "      <td>0.001945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.055526</td>\n",
       "      <td>0.005443</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'C': 0.0001, 'solver': 'sag'}</td>\n",
       "      <td>0.802405</td>\n",
       "      <td>0.795533</td>\n",
       "      <td>0.775945</td>\n",
       "      <td>0.799244</td>\n",
       "      <td>0.807494</td>\n",
       "      <td>0.793814</td>\n",
       "      <td>0.803093</td>\n",
       "      <td>0.800344</td>\n",
       "      <td>0.789275</td>\n",
       "      <td>0.796837</td>\n",
       "      <td>0.800344</td>\n",
       "      <td>0.802062</td>\n",
       "      <td>0.795533</td>\n",
       "      <td>0.796837</td>\n",
       "      <td>0.790650</td>\n",
       "      <td>0.796627</td>\n",
       "      <td>0.007235</td>\n",
       "      <td>247</td>\n",
       "      <td>0.796529</td>\n",
       "      <td>0.799794</td>\n",
       "      <td>0.796958</td>\n",
       "      <td>0.794312</td>\n",
       "      <td>0.797663</td>\n",
       "      <td>0.797732</td>\n",
       "      <td>0.797302</td>\n",
       "      <td>0.798505</td>\n",
       "      <td>0.796117</td>\n",
       "      <td>0.796117</td>\n",
       "      <td>0.797388</td>\n",
       "      <td>0.796443</td>\n",
       "      <td>0.796786</td>\n",
       "      <td>0.797491</td>\n",
       "      <td>0.795773</td>\n",
       "      <td>0.796994</td>\n",
       "      <td>0.001222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.087181</td>\n",
       "      <td>0.009189</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 0.0001, 'solver': 'saga'}</td>\n",
       "      <td>0.802405</td>\n",
       "      <td>0.795876</td>\n",
       "      <td>0.775945</td>\n",
       "      <td>0.798900</td>\n",
       "      <td>0.807838</td>\n",
       "      <td>0.793127</td>\n",
       "      <td>0.803093</td>\n",
       "      <td>0.800344</td>\n",
       "      <td>0.789618</td>\n",
       "      <td>0.797181</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.801718</td>\n",
       "      <td>0.795533</td>\n",
       "      <td>0.796837</td>\n",
       "      <td>0.790650</td>\n",
       "      <td>0.796604</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>248</td>\n",
       "      <td>0.796872</td>\n",
       "      <td>0.799880</td>\n",
       "      <td>0.796529</td>\n",
       "      <td>0.794570</td>\n",
       "      <td>0.798093</td>\n",
       "      <td>0.797474</td>\n",
       "      <td>0.797302</td>\n",
       "      <td>0.798505</td>\n",
       "      <td>0.796202</td>\n",
       "      <td>0.796288</td>\n",
       "      <td>0.797388</td>\n",
       "      <td>0.796357</td>\n",
       "      <td>0.796615</td>\n",
       "      <td>0.797577</td>\n",
       "      <td>0.795773</td>\n",
       "      <td>0.797028</td>\n",
       "      <td>0.001208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.149838</td>\n",
       "      <td>0.013437</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 10000.0, 'solver': 'newton-cg'}</td>\n",
       "      <td>0.861856</td>\n",
       "      <td>0.858419</td>\n",
       "      <td>0.860825</td>\n",
       "      <td>0.862152</td>\n",
       "      <td>0.867652</td>\n",
       "      <td>0.860137</td>\n",
       "      <td>0.859107</td>\n",
       "      <td>0.863574</td>\n",
       "      <td>0.859746</td>\n",
       "      <td>0.869027</td>\n",
       "      <td>0.863574</td>\n",
       "      <td>0.875601</td>\n",
       "      <td>0.864605</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.862730</td>\n",
       "      <td>0.004794</td>\n",
       "      <td>32</td>\n",
       "      <td>0.865183</td>\n",
       "      <td>0.864324</td>\n",
       "      <td>0.865870</td>\n",
       "      <td>0.863734</td>\n",
       "      <td>0.861672</td>\n",
       "      <td>0.864839</td>\n",
       "      <td>0.865097</td>\n",
       "      <td>0.864066</td>\n",
       "      <td>0.864679</td>\n",
       "      <td>0.861328</td>\n",
       "      <td>0.863894</td>\n",
       "      <td>0.859856</td>\n",
       "      <td>0.863722</td>\n",
       "      <td>0.866140</td>\n",
       "      <td>0.864851</td>\n",
       "      <td>0.863950</td>\n",
       "      <td>0.001684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.059227</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 10000.0, 'solver': 'lbfgs'}</td>\n",
       "      <td>0.861856</td>\n",
       "      <td>0.858419</td>\n",
       "      <td>0.860825</td>\n",
       "      <td>0.862152</td>\n",
       "      <td>0.867652</td>\n",
       "      <td>0.860137</td>\n",
       "      <td>0.859107</td>\n",
       "      <td>0.863574</td>\n",
       "      <td>0.859746</td>\n",
       "      <td>0.869027</td>\n",
       "      <td>0.863574</td>\n",
       "      <td>0.875601</td>\n",
       "      <td>0.864605</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.862730</td>\n",
       "      <td>0.004794</td>\n",
       "      <td>32</td>\n",
       "      <td>0.865183</td>\n",
       "      <td>0.864324</td>\n",
       "      <td>0.865870</td>\n",
       "      <td>0.863734</td>\n",
       "      <td>0.861672</td>\n",
       "      <td>0.864839</td>\n",
       "      <td>0.865097</td>\n",
       "      <td>0.864066</td>\n",
       "      <td>0.864765</td>\n",
       "      <td>0.861328</td>\n",
       "      <td>0.863980</td>\n",
       "      <td>0.859856</td>\n",
       "      <td>0.863722</td>\n",
       "      <td>0.866140</td>\n",
       "      <td>0.864851</td>\n",
       "      <td>0.863962</td>\n",
       "      <td>0.001686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.126665</td>\n",
       "      <td>0.016549</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10000.0, 'solver': 'liblinear'}</td>\n",
       "      <td>0.861856</td>\n",
       "      <td>0.858419</td>\n",
       "      <td>0.860825</td>\n",
       "      <td>0.862152</td>\n",
       "      <td>0.867652</td>\n",
       "      <td>0.860137</td>\n",
       "      <td>0.859107</td>\n",
       "      <td>0.863574</td>\n",
       "      <td>0.859746</td>\n",
       "      <td>0.869027</td>\n",
       "      <td>0.863574</td>\n",
       "      <td>0.875601</td>\n",
       "      <td>0.864605</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.862730</td>\n",
       "      <td>0.004794</td>\n",
       "      <td>32</td>\n",
       "      <td>0.865183</td>\n",
       "      <td>0.864410</td>\n",
       "      <td>0.865870</td>\n",
       "      <td>0.863734</td>\n",
       "      <td>0.861672</td>\n",
       "      <td>0.864839</td>\n",
       "      <td>0.865097</td>\n",
       "      <td>0.863980</td>\n",
       "      <td>0.864679</td>\n",
       "      <td>0.861328</td>\n",
       "      <td>0.863980</td>\n",
       "      <td>0.859856</td>\n",
       "      <td>0.863722</td>\n",
       "      <td>0.866140</td>\n",
       "      <td>0.864851</td>\n",
       "      <td>0.863956</td>\n",
       "      <td>0.001685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.111344</td>\n",
       "      <td>0.006990</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'C': 10000.0, 'solver': 'sag'}</td>\n",
       "      <td>0.861856</td>\n",
       "      <td>0.858419</td>\n",
       "      <td>0.860825</td>\n",
       "      <td>0.862152</td>\n",
       "      <td>0.867652</td>\n",
       "      <td>0.860137</td>\n",
       "      <td>0.859107</td>\n",
       "      <td>0.863574</td>\n",
       "      <td>0.859746</td>\n",
       "      <td>0.869027</td>\n",
       "      <td>0.863574</td>\n",
       "      <td>0.875601</td>\n",
       "      <td>0.864605</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.862730</td>\n",
       "      <td>0.004794</td>\n",
       "      <td>32</td>\n",
       "      <td>0.865183</td>\n",
       "      <td>0.864324</td>\n",
       "      <td>0.865870</td>\n",
       "      <td>0.863734</td>\n",
       "      <td>0.861672</td>\n",
       "      <td>0.864839</td>\n",
       "      <td>0.865183</td>\n",
       "      <td>0.864066</td>\n",
       "      <td>0.864765</td>\n",
       "      <td>0.861328</td>\n",
       "      <td>0.863894</td>\n",
       "      <td>0.859856</td>\n",
       "      <td>0.863722</td>\n",
       "      <td>0.866140</td>\n",
       "      <td>0.864765</td>\n",
       "      <td>0.863956</td>\n",
       "      <td>0.001688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.069352</td>\n",
       "      <td>0.003888</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'C': 10000.0, 'solver': 'saga'}</td>\n",
       "      <td>0.861856</td>\n",
       "      <td>0.858419</td>\n",
       "      <td>0.860825</td>\n",
       "      <td>0.862152</td>\n",
       "      <td>0.867652</td>\n",
       "      <td>0.860137</td>\n",
       "      <td>0.859450</td>\n",
       "      <td>0.863574</td>\n",
       "      <td>0.859746</td>\n",
       "      <td>0.869027</td>\n",
       "      <td>0.863574</td>\n",
       "      <td>0.875258</td>\n",
       "      <td>0.864605</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.862730</td>\n",
       "      <td>0.004716</td>\n",
       "      <td>32</td>\n",
       "      <td>0.865183</td>\n",
       "      <td>0.864324</td>\n",
       "      <td>0.865870</td>\n",
       "      <td>0.863734</td>\n",
       "      <td>0.861672</td>\n",
       "      <td>0.864839</td>\n",
       "      <td>0.865183</td>\n",
       "      <td>0.864066</td>\n",
       "      <td>0.864679</td>\n",
       "      <td>0.861328</td>\n",
       "      <td>0.863980</td>\n",
       "      <td>0.859856</td>\n",
       "      <td>0.863722</td>\n",
       "      <td>0.866140</td>\n",
       "      <td>0.864851</td>\n",
       "      <td>0.863962</td>\n",
       "      <td>0.001688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_C  \\\n",
       "0         0.221485      0.104977         0.002029        0.002543   0.0001   \n",
       "1         0.037484      0.022329         0.000917        0.000491   0.0001   \n",
       "2         0.046164      0.003804         0.000812        0.000094   0.0001   \n",
       "3         0.055526      0.005443         0.000738        0.000246   0.0001   \n",
       "4         0.087181      0.009189         0.000794        0.000278   0.0001   \n",
       "..             ...           ...              ...             ...      ...   \n",
       "245       0.149838      0.013437         0.000758        0.000075  10000.0   \n",
       "246       0.059227      0.003720         0.000661        0.000073  10000.0   \n",
       "247       0.126665      0.016549         0.000866        0.000169  10000.0   \n",
       "248       0.111344      0.006990         0.000638        0.000054  10000.0   \n",
       "249       0.069352      0.003888         0.000620        0.000034  10000.0   \n",
       "\n",
       "    param_solver                                 params  split0_test_score  \\\n",
       "0      newton-cg   {'C': 0.0001, 'solver': 'newton-cg'}           0.802405   \n",
       "1          lbfgs       {'C': 0.0001, 'solver': 'lbfgs'}           0.802405   \n",
       "2      liblinear   {'C': 0.0001, 'solver': 'liblinear'}           0.814777   \n",
       "3            sag         {'C': 0.0001, 'solver': 'sag'}           0.802405   \n",
       "4           saga        {'C': 0.0001, 'solver': 'saga'}           0.802405   \n",
       "..           ...                                    ...                ...   \n",
       "245    newton-cg  {'C': 10000.0, 'solver': 'newton-cg'}           0.861856   \n",
       "246        lbfgs      {'C': 10000.0, 'solver': 'lbfgs'}           0.861856   \n",
       "247    liblinear  {'C': 10000.0, 'solver': 'liblinear'}           0.861856   \n",
       "248          sag        {'C': 10000.0, 'solver': 'sag'}           0.861856   \n",
       "249         saga       {'C': 10000.0, 'solver': 'saga'}           0.861856   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0             0.795876           0.775945           0.798900   \n",
       "1             0.795876           0.775945           0.798900   \n",
       "2             0.812715           0.808935           0.817807   \n",
       "3             0.795533           0.775945           0.799244   \n",
       "4             0.795876           0.775945           0.798900   \n",
       "..                 ...                ...                ...   \n",
       "245           0.858419           0.860825           0.862152   \n",
       "246           0.858419           0.860825           0.862152   \n",
       "247           0.858419           0.860825           0.862152   \n",
       "248           0.858419           0.860825           0.862152   \n",
       "249           0.858419           0.860825           0.862152   \n",
       "\n",
       "     split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0             0.807838           0.793127           0.803093   \n",
       "1             0.807838           0.793127           0.803093   \n",
       "2             0.829838           0.813402           0.818900   \n",
       "3             0.807494           0.793814           0.803093   \n",
       "4             0.807838           0.793127           0.803093   \n",
       "..                 ...                ...                ...   \n",
       "245           0.867652           0.860137           0.859107   \n",
       "246           0.867652           0.860137           0.859107   \n",
       "247           0.867652           0.860137           0.859107   \n",
       "248           0.867652           0.860137           0.859107   \n",
       "249           0.867652           0.860137           0.859450   \n",
       "\n",
       "     split7_test_score  split8_test_score  split9_test_score  \\\n",
       "0             0.800344           0.789618           0.797181   \n",
       "1             0.800344           0.789618           0.797181   \n",
       "2             0.818557           0.812650           0.823651   \n",
       "3             0.800344           0.789275           0.796837   \n",
       "4             0.800344           0.789618           0.797181   \n",
       "..                 ...                ...                ...   \n",
       "245           0.863574           0.859746           0.869027   \n",
       "246           0.863574           0.859746           0.869027   \n",
       "247           0.863574           0.859746           0.869027   \n",
       "248           0.863574           0.859746           0.869027   \n",
       "249           0.863574           0.859746           0.869027   \n",
       "\n",
       "     split10_test_score  split11_test_score  split12_test_score  \\\n",
       "0              0.800000            0.801718            0.795533   \n",
       "1              0.800000            0.801718            0.795533   \n",
       "2              0.823024            0.822680            0.817526   \n",
       "3              0.800344            0.802062            0.795533   \n",
       "4              0.800000            0.801718            0.795533   \n",
       "..                  ...                 ...                 ...   \n",
       "245            0.863574            0.875601            0.864605   \n",
       "246            0.863574            0.875601            0.864605   \n",
       "247            0.863574            0.875601            0.864605   \n",
       "248            0.863574            0.875601            0.864605   \n",
       "249            0.863574            0.875258            0.864605   \n",
       "\n",
       "     split13_test_score  split14_test_score  mean_test_score  std_test_score  \\\n",
       "0              0.796837            0.790650         0.796604        0.007230   \n",
       "1              0.796837            0.790650         0.796604        0.007230   \n",
       "2              0.814713            0.810244         0.817295        0.005504   \n",
       "3              0.796837            0.790650         0.796627        0.007235   \n",
       "4              0.796837            0.790650         0.796604        0.007230   \n",
       "..                  ...                 ...              ...             ...   \n",
       "245            0.857339            0.857339         0.862730        0.004794   \n",
       "246            0.857339            0.857339         0.862730        0.004794   \n",
       "247            0.857339            0.857339         0.862730        0.004794   \n",
       "248            0.857339            0.857339         0.862730        0.004794   \n",
       "249            0.857339            0.857339         0.862730        0.004716   \n",
       "\n",
       "     rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                248            0.796872            0.799880   \n",
       "1                248            0.796872            0.799966   \n",
       "2                242            0.819385            0.818010   \n",
       "3                247            0.796529            0.799794   \n",
       "4                248            0.796872            0.799880   \n",
       "..               ...                 ...                 ...   \n",
       "245               32            0.865183            0.864324   \n",
       "246               32            0.865183            0.864324   \n",
       "247               32            0.865183            0.864410   \n",
       "248               32            0.865183            0.864324   \n",
       "249               32            0.865183            0.864324   \n",
       "\n",
       "     split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0              0.796529            0.794570            0.798093   \n",
       "1              0.796529            0.794570            0.798093   \n",
       "2              0.819471            0.818455            0.815792   \n",
       "3              0.796958            0.794312            0.797663   \n",
       "4              0.796529            0.794570            0.798093   \n",
       "..                  ...                 ...                 ...   \n",
       "245            0.865870            0.863734            0.861672   \n",
       "246            0.865870            0.863734            0.861672   \n",
       "247            0.865870            0.863734            0.861672   \n",
       "248            0.865870            0.863734            0.861672   \n",
       "249            0.865870            0.863734            0.861672   \n",
       "\n",
       "     split5_train_score  split6_train_score  split7_train_score  \\\n",
       "0              0.797474            0.797388            0.798505   \n",
       "1              0.797474            0.797388            0.798505   \n",
       "2              0.818440            0.818611            0.819213   \n",
       "3              0.797732            0.797302            0.798505   \n",
       "4              0.797474            0.797302            0.798505   \n",
       "..                  ...                 ...                 ...   \n",
       "245            0.864839            0.865097            0.864066   \n",
       "246            0.864839            0.865097            0.864066   \n",
       "247            0.864839            0.865097            0.863980   \n",
       "248            0.864839            0.865183            0.864066   \n",
       "249            0.864839            0.865183            0.864066   \n",
       "\n",
       "     split8_train_score  split9_train_score  split10_train_score  \\\n",
       "0              0.796202            0.796288             0.797388   \n",
       "1              0.796202            0.796288             0.797388   \n",
       "2              0.818455            0.813042             0.815174   \n",
       "3              0.796117            0.796117             0.797388   \n",
       "4              0.796202            0.796288             0.797388   \n",
       "..                  ...                 ...                  ...   \n",
       "245            0.864679            0.861328             0.863894   \n",
       "246            0.864765            0.861328             0.863980   \n",
       "247            0.864679            0.861328             0.863980   \n",
       "248            0.864765            0.861328             0.863894   \n",
       "249            0.864679            0.861328             0.863980   \n",
       "\n",
       "     split11_train_score  split12_train_score  split13_train_score  \\\n",
       "0               0.796357             0.796615             0.797577   \n",
       "1               0.796357             0.796615             0.797577   \n",
       "2               0.815003             0.818268             0.820088   \n",
       "3               0.796443             0.796786             0.797491   \n",
       "4               0.796357             0.796615             0.797577   \n",
       "..                   ...                  ...                  ...   \n",
       "245             0.859856             0.863722             0.866140   \n",
       "246             0.859856             0.863722             0.866140   \n",
       "247             0.859856             0.863722             0.866140   \n",
       "248             0.859856             0.863722             0.866140   \n",
       "249             0.859856             0.863722             0.866140   \n",
       "\n",
       "     split14_train_score  mean_train_score  std_train_score  \n",
       "0               0.795773          0.797034         0.001210  \n",
       "1               0.795773          0.797040         0.001223  \n",
       "2               0.818627          0.817736         0.001945  \n",
       "3               0.795773          0.796994         0.001222  \n",
       "4               0.795773          0.797028         0.001208  \n",
       "..                   ...               ...              ...  \n",
       "245             0.864851          0.863950         0.001684  \n",
       "246             0.864851          0.863962         0.001686  \n",
       "247             0.864851          0.863956         0.001685  \n",
       "248             0.864765          0.863956         0.001688  \n",
       "249             0.864851          0.863962         0.001688  \n",
       "\n",
       "[250 rows x 42 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06329651",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a804d7",
   "metadata": {},
   "source": [
    "### Default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "838b2a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% de acierto: \n",
      "0.7472164948453608\n",
      "Matrix Confusion: \n",
      "[[1224  735]\n",
      " [ 491 2400]]\n",
      "Clasification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.62      0.67      1959\n",
      "           1       0.77      0.83      0.80      2891\n",
      "\n",
      "    accuracy                           0.75      4850\n",
      "   macro avg       0.74      0.73      0.73      4850\n",
      "weighted avg       0.74      0.75      0.74      4850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_norm, \n",
    "    y, \n",
    "    test_size=0.25, \n",
    "    random_state=0,\n",
    "    shuffle = True)\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "print(\"% de acierto: \")\n",
    "print(np.mean(y_pred == y_test))\n",
    "print(\"Matrix Confusion: \")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"Clasification report: \")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c6caa6",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec724231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Mejores hiperparámetros encontrados (cv)\n",
      "----------------------------------------\n",
      "{'C': 0.26366508987303555, 'gamma': 'scale', 'kernel': 'rbf'} : 0.8575743324694431 accuracy\n",
      "----------------------------------------\n",
      "% de acierto: \n",
      "0.8575257731958763\n",
      "----------------------------------------\n",
      "Matrix Confusion: \n",
      "[[1588  371]\n",
      " [ 320 2571]]\n",
      "----------------------------------------\n",
      "Clasification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82      1959\n",
      "           1       0.87      0.89      0.88      2891\n",
      "\n",
      "    accuracy                           0.86      4850\n",
      "   macro avg       0.85      0.85      0.85      4850\n",
      "weighted avg       0.86      0.86      0.86      4850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.25, random_state=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Grid de hiperparámetros\n",
    "# ==============================================================================\n",
    "param_grid = {'C': np.logspace(-5, 7, 20),\n",
    "              'kernel' : ['poly', 'rbf', 'sigmoid'],\n",
    "              'gamma' : ['scale', 'auto']\n",
    "             }\n",
    "\n",
    "# Búsqueda por validación cruzada\n",
    "# ==============================================================================\n",
    "grid = GridSearchCV(\n",
    "        estimator  = SVC(),\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'accuracy',\n",
    "        n_jobs     = -1,\n",
    "        cv         = 3, \n",
    "        verbose    = 0,\n",
    "        return_train_score = True\n",
    "      )\n",
    "\n",
    "# Se asigna el resultado a _ para que no se imprima por pantalla\n",
    "_ = grid.fit(X = X_train, y = y_train)\n",
    "\n",
    "# Resultados del grid\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(grid.cv_results_)\n",
    "resultados.filter(regex = '(param.*|mean_t|std_t)')\\\n",
    "    .drop(columns = 'params')\\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)\n",
    "\n",
    "\n",
    "# Mejores hiperparámetros por validación cruzada\n",
    "# ==============================================================================\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Mejores hiperparámetros encontrados (cv)\")\n",
    "print(\"----------------------------------------\")\n",
    "print(grid.best_params_, \":\", grid.best_score_, grid.scoring)\n",
    "print(\"----------------------------------------\")\n",
    "\n",
    "\n",
    "modelo_final = grid.best_estimator_\n",
    "y_pred = modelo_final.predict(X_test)\n",
    "\n",
    "print(\"% de acierto: \")\n",
    "print(np.mean(y_pred == y_test))\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Matrix Confusion: \")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Clasification report: \")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e64432",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627f1537",
   "metadata": {},
   "source": [
    "### Default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f5b3e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% de acierto: \n",
      "75.01030927835052\n",
      "-------------------\n",
      "Matrix Confusion: \n",
      "[[1375  584]\n",
      " [ 628 2263]]\n",
      "-------------------\n",
      "Clasification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.69      1959\n",
      "           1       0.79      0.78      0.79      2891\n",
      "\n",
      "    accuracy                           0.75      4850\n",
      "   macro avg       0.74      0.74      0.74      4850\n",
      "weighted avg       0.75      0.75      0.75      4850\n",
      "\n",
      "-------------------\n",
      "Profundidad del árbol: 23\n",
      "Número de nodos terminales: 1526\n",
      "Importancia de los predictores en el modelo\n",
      "-------------------------------------------\n",
      "    importancia\n",
      "18     0.222056\n",
      "0      0.218326\n",
      "3      0.050699\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.25, random_state=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"% de acierto: \")\n",
    "print(np.mean(y_pred == y_test)*100)\n",
    "print(\"-------------------\")\n",
    "print(\"Matrix Confusion: \")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"-------------------\")\n",
    "print(\"Clasification report: \")\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"-------------------\")\n",
    "\n",
    "\n",
    "print(f\"Profundidad del árbol: {dtc.get_depth()}\")\n",
    "print(f\"Número de nodos terminales: {dtc.get_n_leaves()}\")\n",
    "importancia_predictores = pd.DataFrame(\n",
    "                            {'importancia': dtc.feature_importances_}\n",
    "                            )\n",
    "print(\"Importancia de los predictores en el modelo\")\n",
    "print(\"-------------------------------------------\")\n",
    "print(importancia_predictores.sort_values('importancia', ascending=False).head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b2c158",
   "metadata": {},
   "source": [
    "Las columnas 0 y 18 del dataset X corresponden con 'FG_PCT_home' y 'FG_PCT_away' respectivamente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0123feed",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1e1b200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Mejores hiperparámetros encontrados (cv)\n",
      "----------------------------------------\n",
      "{'ccp_alpha': 0.0, 'criterion': 'entropy', 'max_features': 'auto'} : 0.7408570725958304 accuracy\n",
      "----------------------------------------\n",
      "% de acierto: \n",
      "0.7498969072164948\n",
      "----------------------------------------\n",
      "Matrix Confusion: \n",
      "[[1358  601]\n",
      " [ 612 2279]]\n",
      "----------------------------------------\n",
      "Clasification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69      1959\n",
      "           1       0.79      0.79      0.79      2891\n",
      "\n",
      "    accuracy                           0.75      4850\n",
      "   macro avg       0.74      0.74      0.74      4850\n",
      "weighted avg       0.75      0.75      0.75      4850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.25, random_state=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Grid de hiperparámetros\n",
    "# ==============================================================================\n",
    "param_grid = {'ccp_alpha':np.linspace(0, 5, 10),\n",
    "              'criterion' : [\"gini\", \"entropy\"],\n",
    "              'max_features' : [\"auto\", \"sqrt\", \"log2\"],\n",
    "              }\n",
    "\n",
    "# Búsqueda por validación cruzada\n",
    "# ==============================================================================\n",
    "grid = GridSearchCV(\n",
    "        estimator  = DecisionTreeClassifier(),\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'accuracy',\n",
    "        n_jobs     = -1,\n",
    "        cv         = 3, \n",
    "        verbose    = 0,\n",
    "        return_train_score = True\n",
    "      )\n",
    "\n",
    "# Se asigna el resultado a _ para que no se imprima por pantalla\n",
    "_ = grid.fit(X = X_train, y = y_train)\n",
    "\n",
    "# Resultados del grid\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(grid.cv_results_)\n",
    "resultados.filter(regex = '(param.*|mean_t|std_t)')\\\n",
    "    .drop(columns = 'params')\\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)\n",
    "\n",
    "\n",
    "# Mejores hiperparámetros por validación cruzada\n",
    "# ==============================================================================\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Mejores hiperparámetros encontrados (cv)\")\n",
    "print(\"----------------------------------------\")\n",
    "print(grid.best_params_, \":\", grid.best_score_, grid.scoring)\n",
    "print(\"----------------------------------------\")\n",
    "\n",
    "\n",
    "modelo_final = grid.best_estimator_\n",
    "y_pred = modelo_final.predict(X_test)\n",
    "\n",
    "print(\"% de acierto: \")\n",
    "print(np.mean(y_pred == y_test))\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Matrix Confusion: \")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Clasification report: \")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d537fb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profundidad del árbol: 25\n",
      "Número de nodos terminales: 2198\n",
      "Importancia de los predictores en el modelo\n",
      "-------------------------------------------\n",
      "    importancia\n",
      "0      0.144664\n",
      "18     0.109152\n",
      "2      0.069776\n",
      "17     0.057049\n",
      "20     0.045286\n",
      "3      0.038406\n",
      "21     0.032289\n",
      "34     0.031109\n",
      "1      0.029013\n",
      "27     0.025173\n"
     ]
    }
   ],
   "source": [
    "# Estructura del árbol final\n",
    "# ------------------------------------------------------------------------------\n",
    "print(f\"Profundidad del árbol: {modelo_final.get_depth()}\")\n",
    "print(f\"Número de nodos terminales: {modelo_final.get_n_leaves()}\")\n",
    "importancia_predictores = pd.DataFrame(\n",
    "                            {'importancia': modelo_final.feature_importances_}\n",
    "                            )\n",
    "print(\"Importancia de los predictores en el modelo\")\n",
    "print(\"-------------------------------------------\")\n",
    "print(importancia_predictores.sort_values('importancia', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec63eb9e",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8821e01c",
   "metadata": {},
   "source": [
    "### Default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1216e6c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% de acierto: \n",
      "0.8441237113402061\n",
      "Matrix Confusion: \n",
      "[[1528  431]\n",
      " [ 325 2566]]\n",
      "Clasification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80      1959\n",
      "           1       0.86      0.89      0.87      2891\n",
      "\n",
      "    accuracy                           0.84      4850\n",
      "   macro avg       0.84      0.83      0.84      4850\n",
      "weighted avg       0.84      0.84      0.84      4850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.25, random_state=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"% de acierto: \")\n",
    "print(np.mean(y_pred == y_test))\n",
    "print(\"Matrix Confusion: \")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"Clasification report: \")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107dd6d5",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06add4d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3874/324049471.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Se asigna el resultado a _ para que no se imprima por pantalla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Resultados del grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.25, random_state=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Grid de hiperparámetros\n",
    "# ==============================================================================\n",
    "param_grid = {'n_estimators' : [50, 100, 150, 200, 250, 300, 350, 400, 450, 500],\n",
    "              'max_depth'    : [None, 3, 10, 20],\n",
    "              'criterion'    : ['gini', 'entropy'],\n",
    "              'max_features' : [\"auto\", \"sqrt\", \"log2\"],\n",
    "             }\n",
    "\n",
    "# Búsqueda por grid search con validación cruzada\n",
    "# ==============================================================================\n",
    "grid = GridSearchCV(\n",
    "        estimator  = RandomForestClassifier(random_state = 123),\n",
    "        param_grid = param_grid,\n",
    "        scoring    = 'accuracy',\n",
    "        n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "        cv         = RepeatedKFold(n_splits=5, n_repeats=3, random_state=123), \n",
    "        refit      = True,\n",
    "        verbose    = 0,\n",
    "        return_train_score = True\n",
    "       )\n",
    "\n",
    "# Se asigna el resultado a _ para que no se imprima por pantalla\n",
    "_ = grid.fit(X = X_train, y = y_train)\n",
    "\n",
    "# Resultados del grid\n",
    "# ==============================================================================\n",
    "resultados = pd.DataFrame(grid.cv_results_)\n",
    "resultados.filter(regex = '(param.*|mean_t|std_t)')\\\n",
    "    .drop(columns = 'params')\\\n",
    "    .sort_values('mean_test_score', ascending = False) \\\n",
    "    .head(4)\n",
    "\n",
    "\n",
    "# Mejores hiperparámetros por validación cruzada\n",
    "# ==============================================================================\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Mejores hiperparámetros encontrados (cv)\")\n",
    "print(\"----------------------------------------\")\n",
    "print(grid.best_params_, \":\", grid.best_score_, grid.scoring)\n",
    "print(\"----------------------------------------\")\n",
    "\n",
    "\n",
    "modelo_final = grid.best_estimator_\n",
    "y_pred = modelo_final.predict(X_test)\n",
    "\n",
    "print(\"% de acierto: \")\n",
    "print(np.mean(y_pred == y_test))\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Matrix Confusion: \")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"----------------------------------------\")\n",
    "print(\"Clasification report: \")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f598a5c",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9d261cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe de resultados de accuracy\n",
    "columnas_opt = ['Tecnica','Gaussian','Logistic Regression','SVC','Decissin Tree Classifier','Random Forest Classifier']\n",
    "df_opt = pd.DataFrame(columns = columnas_opt)\n",
    "df_opt.set_index(\"Tecnica\",inplace=True)\n",
    "df_opt.loc['Standard'] = [0, 0, 0, 0, 0]\n",
    "df_opt.loc['GridSearch'] = [0, 0, 0, 0, 0]\n",
    "df_opt.loc['RandomSearch'] = [0, 0, 0, 0, 0]\n",
    "df_opt.loc['Hyperopt'] = [0, 0, 0, 0, 0]\n",
    "df_opt.head()\n",
    "\n",
    "columnas_ps = ['Estimator', 'Params', 'Score']\n",
    "df_params_scores = pd.DataFrame(columns = columnas_ps,)\n",
    "\n",
    "X = df.iloc[:,9:44].values\n",
    "y = df.iloc[:,45].values\n",
    "y=y.astype('int')\n",
    "\n",
    "X_copy = X.copy()\n",
    "X_norm = (X_copy - X_copy.mean()) / X_copy.std()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.25, random_state=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efed8da",
   "metadata": {},
   "source": [
    "### 1. Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "68e92cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gaussian</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>SVC</th>\n",
       "      <th>Decissin Tree Classifier</th>\n",
       "      <th>Random Forest Classifier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tecnica</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Standard</th>\n",
       "      <td>0.784742</td>\n",
       "      <td>0.859588</td>\n",
       "      <td>0.85732</td>\n",
       "      <td>0.755876</td>\n",
       "      <td>0.852577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GridSearch</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomSearch</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyperopt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Gaussian Logistic Regression      SVC Decissin Tree Classifier  \\\n",
       "Tecnica                                                                        \n",
       "Standard      0.784742            0.859588  0.85732                 0.755876   \n",
       "GridSearch           0                   0        0                        0   \n",
       "RandomSearch         0                   0        0                        0   \n",
       "Hyperopt             0                   0        0                        0   \n",
       "\n",
       "             Random Forest Classifier  \n",
       "Tecnica                                \n",
       "Standard                     0.852577  \n",
       "GridSearch                          0  \n",
       "RandomSearch                        0  \n",
       "Hyperopt                            0  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "logR = LogisticRegression()\n",
    "svc = SVC()\n",
    "dtc = DecisionTreeClassifier()\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "\n",
    "models = [gnb,logR,svc,dtc,rfc]\n",
    "\n",
    "\n",
    "col = 0\n",
    "for model in models:\n",
    "    model.fit(X_train,y_train)\n",
    "    df_opt.iloc[0,col] = model.score(X_test,y_test)\n",
    "    col += 1\n",
    "\n",
    "df_opt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16171d8",
   "metadata": {},
   "source": [
    "### 2. GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "39f4508a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gaussian</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>SVC</th>\n",
       "      <th>Decissin Tree Classifier</th>\n",
       "      <th>Random Forest Classifier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tecnica</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Standard</th>\n",
       "      <td>0.784742</td>\n",
       "      <td>0.859588</td>\n",
       "      <td>0.85732</td>\n",
       "      <td>0.755876</td>\n",
       "      <td>0.852577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GridSearch</th>\n",
       "      <td>0.784742</td>\n",
       "      <td>0.859794</td>\n",
       "      <td>0.858969</td>\n",
       "      <td>0.74433</td>\n",
       "      <td>0.857732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomSearch</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyperopt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Gaussian Logistic Regression       SVC Decissin Tree Classifier  \\\n",
       "Tecnica                                                                         \n",
       "Standard      0.784742            0.859588   0.85732                 0.755876   \n",
       "GridSearch    0.784742            0.859794  0.858969                  0.74433   \n",
       "RandomSearch         0                   0         0                        0   \n",
       "Hyperopt             0                   0         0                        0   \n",
       "\n",
       "             Random Forest Classifier  \n",
       "Tecnica                                \n",
       "Standard                     0.852577  \n",
       "GridSearch                   0.857732  \n",
       "RandomSearch                        0  \n",
       "Hyperopt                            0  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gaussian\n",
    "var_smoothing = [0.00000001, 0.000000001, 0.0000000001]\n",
    "\n",
    "gnb_grid = dict(var_smoothing = var_smoothing)\n",
    "\n",
    "\n",
    "#Logistic Regression\n",
    "C = np.logspace(-4, 4, 50)\n",
    "solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "logR_grid = dict(C = C,\n",
    "                 solver = solver)\n",
    "\n",
    "\n",
    "\n",
    "#SVC\n",
    "C = np.logspace(-5, 7, 20)\n",
    "kernel = ['poly', 'rbf', 'sigmoid']\n",
    "gamma = ['scale', 'auto']\n",
    "\n",
    "svc_grid = dict(C = C,\n",
    "                kernel = kernel,\n",
    "                gamma = gamma)\n",
    "\n",
    "\n",
    "#Decission Tree Classifier\n",
    "ccp_alpha = np.linspace(0, 5, 10)\n",
    "criterion = [\"gini\", \"entropy\"]\n",
    "max_features = [\"auto\", \"sqrt\", \"log2\"]\n",
    "\n",
    "dtc_grid = dict(ccp_alpha = ccp_alpha,\n",
    "                criterion = criterion,\n",
    "                max_features = max_features,)\n",
    "\n",
    "\n",
    "# Random Forest Classifier\n",
    "n_estimators = [50, 100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
    "max_depth = [None, 3, 10, 20]\n",
    "criterion = ['gini', 'entropy']\n",
    "max_features = [\"auto\", \"sqrt\", \"log2\"]\n",
    "\n",
    "rfc_grid = dict(n_estimators=n_estimators, \n",
    "                max_depth=max_depth,\n",
    "                criterion=criterion,\n",
    "                max_features=max_features)\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------------------#\n",
    "models = [gnb,logR,svc,dtc,rfc]\n",
    "grids = [gnb_grid,logR_grid,svc_grid,dtc_grid,rfc_grid]\n",
    "col = 0\n",
    "fila_aux = 0\n",
    "\n",
    "for ind in range(0,len(models)):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, \n",
    "                                 n_repeats=3, \n",
    "                                 random_state=1)\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=models[col],\n",
    "                               param_grid=grids[col], \n",
    "                               n_jobs=-1, \n",
    "                               cv=cv,\n",
    "                               scoring='accuracy',\n",
    "                               error_score=0)\n",
    "    \n",
    "    grid_clf_acc = grid_search.fit(X_train, y_train)\n",
    "    df_opt.iloc[1,col] = grid_clf_acc.score(X_test,y_test)\n",
    "    \n",
    "    \n",
    "    df_params_scores.loc[fila_aux, 'Estimator'] = grid_clf_acc.estimator\n",
    "    df_params_scores.loc[fila_aux, 'Params'] = str(grid_clf_acc.best_params_)\n",
    "    df_params_scores.loc[fila_aux, 'Score'] = grid_clf_acc.best_score_\n",
    "    \n",
    "    \n",
    "    col += 1\n",
    "    fila_aux += 1\n",
    "\n",
    "df_opt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e67e5dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params_scores.to_csv('df_params_scores_grid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062312ef",
   "metadata": {},
   "source": [
    "### 3. RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "71616a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f1b7ebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_ps = ['Estimator', 'Params', 'Score']\n",
    "df_params_scores_random = pd.DataFrame(columns = columnas_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8f4d1a2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gaussian</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>SVC</th>\n",
       "      <th>Decissin Tree Classifier</th>\n",
       "      <th>Random Forest Classifier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tecnica</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Standard</th>\n",
       "      <td>0.784742</td>\n",
       "      <td>0.859588</td>\n",
       "      <td>0.85732</td>\n",
       "      <td>0.755876</td>\n",
       "      <td>0.852577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GridSearch</th>\n",
       "      <td>0.784742</td>\n",
       "      <td>0.859794</td>\n",
       "      <td>0.858969</td>\n",
       "      <td>0.74433</td>\n",
       "      <td>0.857732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomSearch</th>\n",
       "      <td>0.784742</td>\n",
       "      <td>0.859794</td>\n",
       "      <td>0.830309</td>\n",
       "      <td>0.596082</td>\n",
       "      <td>0.848041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hyperopt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Gaussian Logistic Regression       SVC Decissin Tree Classifier  \\\n",
       "Tecnica                                                                         \n",
       "Standard      0.784742            0.859588   0.85732                 0.755876   \n",
       "GridSearch    0.784742            0.859794  0.858969                  0.74433   \n",
       "RandomSearch  0.784742            0.859794  0.830309                 0.596082   \n",
       "Hyperopt             0                   0         0                        0   \n",
       "\n",
       "             Random Forest Classifier  \n",
       "Tecnica                                \n",
       "Standard                     0.852577  \n",
       "GridSearch                   0.857732  \n",
       "RandomSearch                 0.848041  \n",
       "Hyperopt                            0  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = 0\n",
    "for ind in range(0,len(models)):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, \n",
    "                                 n_repeats=3,\n",
    "                                 random_state=1)\n",
    "    n_iter_search = 3\n",
    "    random_search = RandomizedSearchCV(models[col],\n",
    "                                       param_distributions=grids[col],\n",
    "                                       n_iter=n_iter_search, \n",
    "                                       cv=cv)\n",
    "    \n",
    "    random_search.fit(X_train,y_train)\n",
    "    df_opt.iloc[2,col] = random_search.score(X_test,y_test)\n",
    "    \n",
    "    df_params_scores_random.loc[fila_aux, 'Estimator'] = random_search.estimator\n",
    "    df_params_scores_random.loc[fila_aux, 'Params'] = str(random_search.best_params_)\n",
    "    df_params_scores_random.loc[fila_aux, 'Score'] = random_search.best_score_\n",
    "    \n",
    "    col += 1\n",
    "    fila_aux += 1\n",
    "    \n",
    "df_opt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4ca26cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params_scores_random.to_csv('df_params_scores_random.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcadb32b",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d1a422f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ROC(estimator, data, target):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data,target)\n",
    "\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_hat = estimator.predict(X_test)\n",
    "    probs = estimator.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # plotear curva roc\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "    f, ax = plt.subplots(1,1)\n",
    "    f.set_size_inches(8,7)\n",
    "    ax.plot(fpr,tpr)\n",
    "    ax.plot([0,1], [0,1], c='grey')\n",
    "\n",
    "    print(f'acc: {accuracy_score(y_test, y_hat):.3} \\\n",
    "    recall: {recall_score(y_test, y_hat):.3} \\\n",
    "    precision:{precision_score(y_test, y_hat):.3} \\\n",
    "    f1:{f1_score(y_test, y_hat):.3} \\\n",
    "    auc:{roc_auc_score(y_test, probs):.3}')\n",
    "    \n",
    "    \n",
    "def evaluate_PS(estimator, data, target):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data,target)\n",
    "\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_hat = estimator.predict(X_test)\n",
    "    probs = estimator.predict_proba(X_test)[:,1]\n",
    "\n",
    "    \n",
    "    lr_precision, lr_recall, _ = precision_recall_curve(y_test, probs)\n",
    "    lr_f1, lr_auc = f1_score(y_test, y_hat), auc(lr_recall, lr_precision)\n",
    "    # Resumimos s\n",
    "    print('Estimator: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\n",
    "    # plot the precision-recall curves\n",
    "    no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "    plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='Sin entrenar')\n",
    "    plt.plot(lr_recall, lr_precision, marker='.', label=str(estimator))\n",
    "    #Etiquetas de ejes\n",
    "    plt.xlabel('Sensibilidad')\n",
    "    plt.ylabel('Precisión')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "48ed3d77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsc/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/dsc/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.744     recall: 0.816     precision:0.766     f1:0.79     auc:0.808\n",
      "Estimator: f1=0.802 auc=0.865\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.775     recall: 0.794     precision:0.817     f1:0.805     auc:0.857\n",
      "Estimator: f1=0.811 auc=0.902\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logR = LogisticRegression()\n",
    "evaluate_ROC(logR, X_norm, y)\n",
    "evaluate_PS(logR, X_norm, y)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "evaluate_ROC(gnb, X_norm, y)\n",
    "evaluate_PS(gnb, X_norm, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
